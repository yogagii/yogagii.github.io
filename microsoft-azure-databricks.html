<!--
 * @Author: your name
 * @Date: 2013-11-02 09:09:18
 * @LastEditTime : 2019-12-29 22:05:43
 * @LastEditors  : Please set LastEditors
 * @Description: In User Settings Edit
 * @FilePath: /YogaBlog/pelican-themes/Responsive-Pelican/templates/article.html
 -->
<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
    <title>Frontend Learning Book</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0">
    <link rel="stylesheet" id="responsive-style-css"  href='/theme/css/style.css' type="text/css" media="all" />
    <link rel="stylesheet" id="responsive-style-css"  href='/theme/css/highlight.css' type="text/css" media="all" />
    
</head>

<body id="index" class="blog">
<div id="container" class="hfeed">
    <header id="header" >
        <div id="logo">
          <h1>
            <!-- <img src="/theme/image/default-logo.png" width="300" height="100" alt="小铱的故事" /> -->
            Frontend Learning Book
          </h1>
        </div> <!-- /#logo-->
        <nav id="menu" class="main-nav"><ul class="menu">
            <li  class="active"><a href="/category/javascript.html">Javascript</a></li>
            <li  class="active"><a href="/category/react.html">React</a></li>
            <li  class="active"><a href="/category/ios.html">IOS</a></li>
            <li  class="active"><a href="/category/frontend.html">Frontend</a></li>
            <li  class="active"><a href="/category/analytics.html">Analytics</a></li>
            <li  class="active"><a href="/category/programming.html">Programming</a></li>
            <li  class="active"><a href="/category/project.html">Project</a></li>
            <li  class="active"><a href="/category/backend.html">Backend</a></li>
            <li  class="active"><a href="/category/angular.html">Angular</a></li>
            <li  class="active"><a href="/category/cloud.html">Cloud</a></li>

        </ul></nav><!-- /#menu -->
    </header>
    <section id="wrapper" class="clearfix">
        <section id="content" class="grid col-620" >
                <section class="breadcrumb-list">
<a href="">Blog</a> ›<a href="category/cloud.html">Cloud</a> ›Microsoft Azure&nbsp;Databricks
                </section>


<section id="post" class="post hentry">
    <header>
    <h2 class="post-title" >Microsoft Azure&nbsp;Databricks</h2>
    
    <div class="post-meta">
        <span class="meta-prep">Post in</span>
        <abbr class="date" title="2022-11-22T00:00:00+08:00"> 
            <a href="/archive/2022/11/index.html">二 22 十一月 2022 </a>
        </abbr>
        <span class="meta-prep"> |Tags</span>
                <a href="/tag/azure.html">Azure</a>
                <a href="/tag/etl.html">ETL</a>
        <!-- TOBE COMMENTS -->
    </div>
    </header>
    <div class="post-entry">
        <p>databricks是使用Apache&nbsp;Spark™的原始创建者提供的Databricks统一分析平台。它集成了Spark环境支持Scala、python、R语言进行开发。</p>
<p>adb-xxx.azuredatabricks.net</p>
<h2>Delta&nbsp;Table</h2>
<p>Delta Lake 是经过优化的存储层，它使用基于文件的事务日志扩展了 Parquet 数据文件，可以处理 <span class="caps">ACID</span> 事务和可缩放的元数据。Delta Lake 是 Azure Databricks 上所有操作的默认存储格式。 除非另行指定，否则 Azure Databricks 上的所有表都是 Delta&nbsp;表。</p>
<blockquote>
<p><span class="caps">ACID</span>:&nbsp;原子性、一致性、隔离性、持久性</p>
</blockquote>
<p>Delta Lake 特性：
* 支持ACID事务
* 可扩展的元数据处理
* 统一的流、批处理API接口
* 更新、删除数据，实时读写（读是读当前的最新快照）
* 数据版本控制，根据需要查看历史数据快照，可回滚数据
*&nbsp;自动处理schema变化，可修改表结构</p>
<p>可以使用 <span class="caps">DESCRIBE</span> <span class="caps">DETAIL</span> 检索有关 Delta&nbsp;表的详细信息</p>
<div class="highlight"><pre><span></span><code><span class="k">DESCRIBE</span><span class="w"> </span><span class="n">DETAIL</span><span class="w"> </span><span class="n">eventsTable</span>
</code></pre></div>

<p>返回对表的每次写入的出处信息，包括操作、用户等。 表历史记录会保留 30&nbsp;天。即使parquet文件被vacuum，历史也会保留。</p>
<div class="highlight"><pre><span></span><code><span class="k">DESCRIBE</span><span class="w"> </span><span class="n">HISTORY</span><span class="w"> </span><span class="n">eventsTable</span>
</code></pre></div>

<p>delta表的schema中，字段名的小写不能相同，delta&nbsp;lake区分大小写，但保存时不敏感，而parquet保存时是大小写敏感的</p>
<p>delta表是一个目录，表的根目录除了表数据外，有一个_delta_log目录，用来存放事务日志；事务日志记录了从最初的delta表开始的所有commit事件，每个commit形成一个json文件，文件名是严格递增的，文件名就是版本号。每10个json合并成一个parquet格式的checkpoint文件，记录之前所有的commit。spark读的时候会自动跳到最新的checkpoint，然后再读之后的json；</p>
<p>当多个用户同时写数据时，都是生成一个新版本的数据文件，用互斥锁来决定顺序，拿到锁的，按顺序生成下一个版本的数据文件，然后释放锁，后来的在之前数据的基础上执行他的commit，生成一个新版本的数据。</p>
<p>truncate table不会释放存储空间：Delta Lake 删除操作后，旧数据文件不会被完全删除，仍保留在磁盘上，但在 Delta Lake 事务日志中记录为“tombstoned”（不再是活动表的一部分）。可以通过time travel回到表的早期版本，如果要删除超过某个时间段的文件，可以使用 <span class="caps">VACUUM</span> 以递归方式清空与 Spark 表关联的目录，并删除超过保留期阈值的未提交文件。 默认阈值为 7&nbsp;天。</p>
<div class="highlight"><pre><span></span><code><span class="k">select</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="k">table_name</span><span class="w"> </span><span class="k">VERSION</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="k">OF</span><span class="w"> </span><span class="mi">100</span>
<span class="c1">-- 回滚</span>
<span class="n">RESTORE</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="k">table_name</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="k">TO</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="n">time_travel_version</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1">-- 清理</span>
<span class="k">VACUUM</span><span class="w"> </span><span class="k">table_name</span><span class="w"> </span><span class="p">[</span><span class="n">RETAIN</span><span class="w"> </span><span class="n">num</span><span class="w"> </span><span class="n">HOURS</span><span class="p">]</span><span class="w"> </span><span class="p">[</span><span class="n">DRY</span><span class="w"> </span><span class="n">RUN</span><span class="p">]</span>
</code></pre></div>

<p>Vacuum 后可在 Storage Explorer 对应表的文件夹下 Folder Statictis 看到 Active blob明显减少，但是当 Storage Account 启用了软删除 Data protection -&gt; Enable soft delete for blobs / containers 时，Total&nbsp;数量不会减少，在软删除有效期内删除的文件可以在portal上看到并还原，有效期过后会永久删除</p>
<p>Delta lake 优点：
* 实时查询，支持ACID功能，保证了数据流入和查询的隔离性，不会产生脏数据。
* Delta支持数据的删除或更新，数据实时同步 <span class="caps">CDC</span>：使用Delta merge功能，启动流作业，实时将上游的数据通过merge更新到Delta Lake中。
* 数据质量控制：借助于Delta&nbsp;Schema校验功能，在数据导入时剔除异常数据，或者对异常数据做进一步处理。</p>
<p>Delta lake 缺点：
* 更新操作很重，更新一条数据和更新一批数据的成本可能是一样的，所以不适合一条条的更新数据
* 更新数据的方式是新增文件，会造成文件数量过多，需要清理历史版本的数据
*&nbsp;乐观锁的并发能力较差，更适合写少读多的场景</p>
<p><em>踩坑：用 <span class="caps">ADF</span> 将.parquet文件存储到sql server时，delta table格式会保留下全部数据文件，将需要转存sql server的表（dm和dim，需要update的表不行）改为 <span class="caps">USING</span> parquet，parquet&nbsp;表可每次truncate后全量更新，需保证字段格式严格按照ddl中定义的格式.</em></p>
<p>只有 Delta lake table支持的语句：
* <span class="caps">DELETE</span> <span class="caps">FROM</span>
* <span class="caps">UPDATE</span>
* <span class="caps">MERGE</span> <span class="caps">INTO</span>
* <span class="caps">CLONE</span>
* <span class="caps">CACHE</span>
* <span class="caps">COPY</span> <span class="caps">INTO</span>
* <span class="caps">DESCRIBE</span> <span class="caps">HISTORY</span>
* <span class="caps">VACUUM</span>
* <span class="caps">RESTORE</span></p>
<h2>Delta Live Table&nbsp;增量实时表</h2>
<div class="highlight"><pre><span></span><code><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="n">REFRESH</span><span class="w"> </span><span class="n">STREAMING</span><span class="w"> </span><span class="n">LIVE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">customers_silver</span>
<span class="k">AS</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">STREAM</span><span class="p">(</span><span class="n">LIVE</span><span class="p">.</span><span class="n">customers_bronze</span><span class="p">)</span>
</code></pre></div>

<p>当为管道触发更新时，流式处理表或视图仅处理自上次更新以来到达的新数据。&nbsp;增量实时表运行时会自动跟踪已处理的数据。</p>
<h2><span class="caps">SQL</span></h2>
<ul>
<li>自定义变量</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">SET</span><span class="w"> </span><span class="n">delDate</span><span class="o">=</span><span class="k">current_date</span><span class="p">();</span>
<span class="k">set</span><span class="w"> </span><span class="n">tableList</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="s1">&#39;TABLE1&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;TABLE2&#39;</span><span class="p">);</span>

<span class="k">delete</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="o">&lt;</span><span class="k">TABLE</span><span class="o">&gt;</span><span class="w"> </span><span class="k">where</span><span class="w"> </span><span class="n">insertDate</span><span class="o">=</span><span class="err">${</span><span class="n">hiveconf</span><span class="p">:</span><span class="n">delDate</span><span class="err">}</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">tablename</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="err">${</span><span class="n">hiveconf</span><span class="p">:</span><span class="n">tableList</span><span class="err">}</span><span class="p">;</span>
</code></pre></div>

<ul>
<li>Useful&nbsp;Function</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">EXCEPT</span><span class="w"> </span><span class="n">insertTime</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="o">&lt;</span><span class="k">table</span><span class="o">&gt;</span><span class="w"> </span><span class="c1">-- 排除指定字段</span>

<span class="k">select</span><span class="w"> </span><span class="n">IFNULL</span><span class="p">(</span><span class="n">M</span><span class="p">.</span><span class="n">MaterialCode</span><span class="p">,</span><span class="w"> </span><span class="n">P</span><span class="p">.</span><span class="n">MaterialCode</span><span class="p">)</span><span class="w"> </span><span class="n">MaterialCode</span><span class="w"> </span><span class="c1">-- IFNULL(A,B) A为空则返回B</span>
<span class="k">select</span><span class="w"> </span><span class="k">ISNULL</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="c1">-- true/false</span>
</code></pre></div>

<ul>
<li>日期<ul>
<li>date_part&nbsp;提取部分日期</li>
<li>date_add 返回在 startDate 之后的日期&nbsp;numDays</li>
<li>date_sub 返回在 startDate 之前的日期&nbsp;numDays</li>
<li>dayofmonth&nbsp;返回这个月的第几天</li>
</ul>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">SET</span><span class="w"> </span><span class="n">DayL1M</span><span class="o">=</span><span class="n">date_sub</span><span class="p">(</span><span class="n">getDate</span><span class="p">(),</span><span class="w"> </span><span class="n">dayofmonth</span><span class="p">(</span><span class="n">getdate</span><span class="p">()));</span><span class="w"> </span><span class="c1">-- 上个月末 20230531</span>
<span class="k">SET</span><span class="w"> </span><span class="n">DayL5M</span><span class="o">=</span><span class="n">date_sub</span><span class="p">(</span><span class="err">${</span><span class="n">hiveconf</span><span class="p">:</span><span class="n">DayL1M</span><span class="err">}</span><span class="p">,</span><span class="w"> </span><span class="mi">155</span><span class="p">);</span><span class="w"> </span><span class="c1">-- 6*31 半年前</span>
<span class="k">SET</span><span class="w"> </span><span class="n">DataMonth</span><span class="o">=</span><span class="n">date_part</span><span class="p">(</span><span class="s1">&#39;YEAR&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">${</span><span class="n">hiveconf</span><span class="p">:</span><span class="n">DayL1M</span><span class="err">}</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="o">+</span><span class="n">date_part</span><span class="p">(</span><span class="s1">&#39;MONTHS&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">${</span><span class="n">hiveconf</span><span class="p">:</span><span class="n">DayL1M</span><span class="err">}</span><span class="p">);</span><span class="w"> </span><span class="c1">-- 上个月 202305</span>
<span class="k">SET</span><span class="w"> </span><span class="n">DataMonthL6</span><span class="o">=</span><span class="n">date_part</span><span class="p">(</span><span class="s1">&#39;YEAR&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">${</span><span class="n">hiveconf</span><span class="p">:</span><span class="n">DayL5M</span><span class="err">}</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="o">+</span><span class="n">date_part</span><span class="p">(</span><span class="s1">&#39;MONTHS&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">${</span><span class="n">hiveconf</span><span class="p">:</span><span class="n">DayL5M</span><span class="err">}</span><span class="p">);</span><span class="w"> </span><span class="c1">-- 6个月前 202212</span>
</code></pre></div>

<ul>
<li>自定义函数</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">FUNCTION</span><span class="w"> </span><span class="n">ToDouble</span><span class="p">(</span><span class="n">value</span><span class="w"> </span><span class="n">STRING</span><span class="p">)</span><span class="w"> </span><span class="k">RETURNS</span><span class="w"> </span><span class="n">DOUBLE</span><span class="w"> </span><span class="k">RETURN</span><span class="w"> </span><span class="n">double</span><span class="p">(</span><span class="k">replace</span><span class="p">(</span><span class="k">replace</span><span class="p">(</span><span class="k">replace</span><span class="p">(</span><span class="k">replace</span><span class="p">(</span><span class="k">trim</span><span class="p">(</span><span class="n">value</span><span class="p">),</span><span class="s1">&#39;-&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">),</span><span class="s1">&#39;&quot;&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">),</span><span class="s1">&#39;,&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">),</span><span class="s1">&#39;/&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">))</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">LandingTable</span> <span class="o">=</span> <span class="s1">&#39;STG.Inventory_CN&#39;</span>
<span class="n">CSTGTable</span> <span class="o">=</span> <span class="s1">&#39;CSTG.Inventory_CN&#39;</span>
<span class="n">TableColumn</span><span class="o">=</span><span class="s1">&#39;WhN, GRDate, PutawayStock&#39;</span>
<span class="n">CleanColumn</span><span class="o">=</span><span class="s2">&quot;WhN, TO_DATE(GRDate,&#39;yyyy/MM/dd&#39;) GRDate, ToDouble(PutawayStock) PutawayStock&quot;</span>

<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INSERT INTO </span><span class="si">{</span><span class="n">CSTGTable</span><span class="si">}</span><span class="s2">(</span><span class="si">{</span><span class="n">TableColumn</span><span class="si">}</span><span class="s2">) SELECT </span><span class="si">{</span><span class="n">CleanColumn</span><span class="si">}</span><span class="s2">, now() from </span><span class="si">{</span><span class="n">LandingTable</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">);</span>
</code></pre></div>

<ul>
<li><span class="caps">MERGE</span> <span class="caps">INTO</span></li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">with</span><span class="w"> </span><span class="err">{</span><span class="n">tablename</span><span class="err">}</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="p">(</span><span class="k">SELECT</span><span class="w"> </span><span class="n">EXPLODE</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="w"> </span><span class="k">data</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">json</span><span class="p">.</span><span class="o">`</span><span class="err">{</span><span class="n">jsonAddress</span><span class="err">}{</span><span class="n">Pre_Tablename</span><span class="err">}{</span><span class="n">tablename</span><span class="err">}</span><span class="o">`</span><span class="p">)</span>

<span class="n">merge</span><span class="w"> </span><span class="k">into</span><span class="w"> </span><span class="o">&lt;</span><span class="k">schema</span><span class="o">&gt;</span><span class="p">.</span><span class="n">Test</span><span class="w"> </span><span class="n">a</span>
<span class="k">using</span><span class="w"> </span><span class="err">{</span><span class="n">tablename</span><span class="err">}</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">id</span><span class="o">=</span><span class="n">b</span><span class="p">.</span><span class="n">id</span><span class="p">)</span><span class="w">  </span>
<span class="k">when</span><span class="w"> </span><span class="n">matched</span><span class="w"> </span><span class="k">then</span><span class="w"> </span><span class="k">update</span><span class="w"> </span>
<span class="w">  </span><span class="k">set</span><span class="w"> </span><span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b</span><span class="p">.</span><span class="n">name</span>
<span class="k">when</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">matched</span><span class="w"> </span><span class="k">then</span><span class="w"> </span><span class="k">insert</span><span class="w"> </span>
<span class="w">  </span><span class="p">(</span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="n">name</span><span class="p">)</span><span class="w"> </span><span class="k">values</span><span class="w"> </span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">.</span><span class="n">name</span><span class="p">);</span>
</code></pre></div>

<ul>
<li>Range join optimization&nbsp;范围联接优化</li>
</ul>
<p>适用范围：
1. 在区间范围内
2. 数据类型：numeric，date (days)，timestamp (second)
3. <span class="caps">INNER</span> <span class="caps">JOIN</span> / <span class="caps">LEFT</span> <span class="caps">OUTER</span> <span class="caps">JOIN</span> / <span class="caps">RIGHT</span> <span class="caps">OUTER</span> <span class="caps">JOIN</span>
4. Have a bin size tuning parameter 箱大小:&nbsp;建议将箱大小设置为值间隔的典型预期长度</p>
<div class="highlight"><pre><span></span><code><span class="c1">--- Point in interval range join</span>
<span class="k">SELECT</span><span class="w"> </span><span class="o">*</span>
<span class="k">FROM</span><span class="w"> </span><span class="n">points</span><span class="w"> </span><span class="k">JOIN</span><span class="w"> </span><span class="n">ranges</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="n">points</span><span class="p">.</span><span class="n">p</span><span class="w"> </span><span class="k">BETWEEN</span><span class="w"> </span><span class="n">ranges</span><span class="p">.</span><span class="k">start</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">ranges</span><span class="p">.</span><span class="k">end</span><span class="p">;</span>

<span class="c1">--- Interval overlap range join</span>
<span class="k">SELECT</span><span class="w"> </span><span class="o">*</span>
<span class="k">FROM</span><span class="w"> </span><span class="n">r1</span><span class="w"> </span><span class="k">JOIN</span><span class="w"> </span><span class="n">r2</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="n">r1</span><span class="p">.</span><span class="k">start</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">r2</span><span class="p">.</span><span class="k">end</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="n">r2</span><span class="p">.</span><span class="k">start</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">r1</span><span class="p">.</span><span class="k">end</span><span class="p">;</span>
</code></pre></div>

<p>Enable range join using a range join&nbsp;hint</p>
<div class="highlight"><pre><span></span><code><span class="k">SELECT</span><span class="w"> </span><span class="cm">/*+ RANGE_JOIN(ranges, 10) */</span><span class="w"> </span><span class="o">*</span>
<span class="k">FROM</span><span class="w"> </span><span class="n">points</span><span class="w"> </span><span class="k">JOIN</span><span class="w"> </span><span class="n">ranges</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="n">points</span><span class="p">.</span><span class="n">p</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">ranges</span><span class="p">.</span><span class="k">start</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="n">points</span><span class="p">.</span><span class="n">p</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">ranges</span><span class="p">.</span><span class="k">end</span><span class="p">;</span>
</code></pre></div>

<ul>
<li>INFORMATION_SCHEMA </li>
</ul>
<p>The INFORMATION_SCHEMA is a <span class="caps">SQL</span> standard based schema, provided in every catalog created on Unity&nbsp;Catalog.</p>
<table>
<thead>
<tr>
<th>Table</th>
<th>Desc</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="caps">CATALOGS</span></td>
<td>Describes catalogs.</td>
</tr>
<tr>
<td><span class="caps">TABLES</span></td>
<td>Describes tables and views defined within the catalog.</td>
</tr>
<tr>
<td><span class="caps">COLUMNS</span></td>
<td>Describes columns of tables and views in the catalog.</td>
</tr>
</tbody>
</table>
<p>https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-information-schema</p>
<div class="highlight"><pre><span></span><code><span class="k">SELECT</span><span class="w"> </span><span class="n">table_owner</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">information_schema</span><span class="p">.</span><span class="n">tables</span><span class="w"> </span><span class="k">WHERE</span><span class="w"> </span><span class="n">table_schema</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;information_schema&#39;</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="k">table_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;columns&#39;</span><span class="p">;</span>

<span class="k">SELECT</span><span class="w"> </span><span class="n">ordinal_position</span><span class="p">,</span><span class="w"> </span><span class="k">column_name</span><span class="p">,</span><span class="w"> </span><span class="n">data_type</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">information_schema</span><span class="p">.</span><span class="n">tables</span>
</code></pre></div>

<p><em>踩坑: AnalysisException: [UC_NOT_ENABLED] Unity Catalog is not enabled on this&nbsp;cluster.</em></p>
<h2>Data Lake Storage&nbsp;Gen2</h2>
<p>如果在 <span class="caps">ADLS</span> Gen2 上配置防火墙，必须配置网络设置以允许 Azure Databricks 工作区连接到 <span class="caps">ADLS</span>&nbsp;Gen2</p>
<p><span class="dquo">&#8220;</span>abfss://<container-name>@<storage-account-name>.dfs.core.windows.net/&#8221; 是 AzureBlob Storage Gen2 文件系统的地址, abfss:/ 是ABFSS 协议 (Azure Blob File System Service)&nbsp;的前缀，指示文件系统的访问协议。</p>
<p><span class="caps">SAS</span> Token: 共享访问签名是指向一个或多个存储资源的已签名 <span class="caps">URI</span>。 该 <span class="caps">URI</span> 包括的令牌包含一组特殊查询参数。&nbsp;该令牌指示客户端可以如何访问资源。 </p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">connectToDatalake</span><span class="p">(</span><span class="n">blob</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.account.auth.type.</span><span class="si">%s</span><span class="s2">.dfs.core.chinacloudapi.cn&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">blob</span><span class="p">),</span> <span class="s2">&quot;SAS&quot;</span><span class="p">)</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.sas.token.provider.type.</span><span class="si">%s</span><span class="s2">.dfs.core.chinacloudapi.cn&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">blob</span><span class="p">),</span> <span class="s2">&quot;org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider&quot;</span><span class="p">)</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.sas.fixed.token.</span><span class="si">%s</span><span class="s2">.dfs.core.chinacloudapi.cn&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">blob</span><span class="p">),</span> <span class="n">token</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">importExcelConfig</span><span class="p">(</span><span class="n">blob</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">_jsc</span><span class="o">.</span><span class="n">hadoopConfiguration</span><span class="p">()</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.account.auth.type.</span><span class="si">%s</span><span class="s2">.dfs.core.chinacloudapi.cn&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">blob</span><span class="p">),</span> <span class="s2">&quot;SAS&quot;</span><span class="p">)</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">_jsc</span><span class="o">.</span><span class="n">hadoopConfiguration</span><span class="p">()</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.sas.token.provider.type.</span><span class="si">%s</span><span class="s2">.dfs.core.chinacloudapi.cn&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">blob</span><span class="p">),</span> <span class="s2">&quot;org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider&quot;</span><span class="p">)</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">_jsc</span><span class="o">.</span><span class="n">hadoopConfiguration</span><span class="p">()</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.sas.fixed.token.</span><span class="si">%s</span><span class="s2">.dfs.core.chinacloudapi.cn&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">blob</span><span class="p">),</span> <span class="n">token</span><span class="p">)</span>
</code></pre></div>

<p>OAuth: 使用 Azure Active Directory (Azure <span class="caps">AD</span>) 应用程序服务主体在 Azure&nbsp;存储帐户中装载数据以进行身份验证。</p>
<div class="highlight"><pre><span></span><code><span class="n">configs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;fs.azure.account.auth.type&quot;</span><span class="p">:</span> <span class="s2">&quot;OAuth&quot;</span><span class="p">,</span>
          <span class="s2">&quot;fs.azure.account.oauth.provider.type&quot;</span><span class="p">:</span> <span class="s2">&quot;org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider&quot;</span><span class="p">,</span>
          <span class="s2">&quot;fs.azure.account.oauth2.client.id&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;application-id&gt;&quot;</span><span class="p">,</span>
          <span class="s2">&quot;fs.azure.account.oauth2.client.secret&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;service-credential-key-name&gt;&quot;</span><span class="p">,</span>
          <span class="s2">&quot;fs.azure.account.oauth2.client.endpoint&quot;</span><span class="p">:</span> <span class="s2">&quot;https://login.microsoftonline.com/&lt;directory-id&gt;/oauth2/token&quot;</span><span class="p">}</span>

<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span>
  <span class="n">source</span> <span class="o">=</span> <span class="s2">&quot;abfss://&lt;container-name&gt;@&lt;storage-account-name&gt;.dfs.core.windows.net/&quot;</span><span class="p">,</span>
  <span class="n">mount_point</span> <span class="o">=</span> <span class="s2">&quot;/mnt/&lt;mount-name&gt;&quot;</span><span class="p">,</span>
  <span class="n">extra_configs</span> <span class="o">=</span> <span class="n">configs</span><span class="p">)</span>
</code></pre></div>

<p>Azure Key Vault: 将 client secret 保存到 Azure Key&nbsp;Vault</p>
<p>https://learn.microsoft.com/zh-cn/azure/databricks/getting-started/connect-to-azure-storage</p>
<p>To reference the client secret stored in an Azure Key Vault, you can create a secret scope backed by Azure Key Vault in Azure Databricks. https://<databricks-instance>#secrets/createScope</p>
<div class="highlight"><pre><span></span><code><span class="n">configs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;fs.azure.account.auth.type&quot;</span><span class="p">:</span> <span class="s2">&quot;OAuth&quot;</span><span class="p">,</span>
          <span class="s2">&quot;fs.azure.account.oauth.provider.type&quot;</span><span class="p">:</span> <span class="s2">&quot;org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider&quot;</span><span class="p">,</span>
          <span class="s2">&quot;fs.azure.account.oauth2.client.id&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;application-id&gt;&quot;</span><span class="p">,</span>
          <span class="s2">&quot;fs.azure.account.oauth2.client.secret&quot;</span><span class="p">:</span> <span class="n">dbutils</span><span class="o">.</span><span class="n">secrets</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;&lt;scope-name&gt;&quot;</span><span class="p">,</span><span class="n">key</span><span class="o">=</span><span class="s2">&quot;&lt;service-credential-key-name&gt;&quot;</span><span class="p">),</span>
          <span class="s2">&quot;fs.azure.account.oauth2.client.endpoint&quot;</span><span class="p">:</span> <span class="s2">&quot;https://login.microsoftonline.com/&lt;directory-id&gt;/oauth2/token&quot;</span><span class="p">}</span>

<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span>
  <span class="n">source</span> <span class="o">=</span> <span class="s2">&quot;abfss://&lt;container-name&gt;@&lt;storage-account-name&gt;.dfs.core.chinacloudapi.cn/&quot;</span><span class="p">,</span>
  <span class="n">mount_point</span> <span class="o">=</span> <span class="s2">&quot;/mnt/&lt;mount-name&gt;&quot;</span><span class="p">,</span>
  <span class="n">extra_configs</span> <span class="o">=</span> <span class="n">configs</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">service_credential</span> <span class="o">=</span> <span class="n">dbutils</span><span class="o">.</span><span class="n">secrets</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;&lt;scope&gt;&quot;</span><span class="p">,</span><span class="n">key</span><span class="o">=</span><span class="s2">&quot;&lt;service-credential-key&gt;&quot;</span><span class="p">)</span>

<span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.account.auth.type.&lt;storage-account&gt;.dfs.core.chinacloudapi.cn&quot;</span><span class="p">,</span> <span class="s2">&quot;OAuth&quot;</span><span class="p">)</span>
<span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.account.oauth.provider.type.&lt;storage-account&gt;.dfs.core.chinacloudapi.cn&quot;</span><span class="p">,</span> <span class="s2">&quot;org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider&quot;</span><span class="p">)</span>
<span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.account.oauth2.client.id.&lt;storage-account&gt;.dfs.core.chinacloudapi.cn&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;application-id&gt;&quot;</span><span class="p">)</span>
<span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.account.oauth2.client.secret.&lt;storage-account&gt;.dfs.core.chinacloudapi.cn&quot;</span><span class="p">,</span> <span class="n">service_credential</span><span class="p">)</span>
<span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.account.oauth2.client.endpoint.&lt;storage-account&gt;.dfs.core.chinacloudapi.cn&quot;</span><span class="p">,</span> <span class="s2">&quot;https://login.microsoftonline.com/&lt;directory-id&gt;/oauth2/token&quot;</span><span class="p">)</span>
</code></pre></div>

<p>mount之后可以创建Schema，然后在schema中建的table数据都会存入湖中</p>
<div class="highlight"><pre><span></span><code><span class="k">CREATE</span><span class="w"> </span><span class="k">SCHEMA</span><span class="w"> </span><span class="n">ads_jointown</span>
<span class="k">LOCATION</span><span class="w"> </span><span class="s1">&#39;/mnt/&lt;mount-name&gt;&#39;</span>
</code></pre></div>

<h2><span class="caps">AWS</span>&nbsp;S3</h2>
<div class="highlight"><pre><span></span><code><span class="n">sc</span><span class="o">.</span><span class="n">_jsc</span><span class="o">.</span><span class="n">hadoopConfiguration</span><span class="p">()</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.s3n.awsAccessKeyId&quot;</span><span class="p">,</span> <span class="s2">&quot;xxx&quot;</span><span class="p">)</span>
<span class="n">sc</span><span class="o">.</span><span class="n">_jsc</span><span class="o">.</span><span class="n">hadoopConfiguration</span><span class="p">()</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.s3n.awsSecretAccessKey&quot;</span><span class="p">,</span><span class="s2">&quot;xxx&quot;</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="s2">&quot;s3://&lt;bucketname&gt;/&lt;folder&gt;/&quot;</span><span class="p">))</span>
</code></pre></div>

<p>ADF不支持用S3作为Sink，只能通过Databricks将数据写入S3</p>
<div class="highlight"><pre><span></span><code><span class="n">pip</span> <span class="n">install</span> <span class="n">boto3</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">from</span> <span class="nn">boto3.session</span> <span class="kn">import</span> <span class="n">Session</span>
<span class="kn">from</span> <span class="nn">botocore.exceptions</span> <span class="kn">import</span> <span class="n">ClientError</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">Session</span><span class="p">(</span><span class="n">access_key</span><span class="p">,</span> <span class="n">secret_key</span><span class="p">)</span>
<span class="n">s3_client</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s1">&#39;s3&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">list_object</span><span class="p">(</span><span class="n">bucketName</span><span class="p">):</span>
    <span class="n">file_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">s3_client</span><span class="o">.</span><span class="n">list_objects_v2</span><span class="p">(</span><span class="n">Bucket</span><span class="o">=</span><span class="n">bucketName</span><span class="p">)</span>
    <span class="n">file_desc</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;Contents&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">file_desc</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;file_name: </span><span class="si">{}</span><span class="s1">, file_size: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="s1">&#39;Key&#39;</span><span class="p">],</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;Size&#39;</span><span class="p">]))</span>
        <span class="n">file_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="s1">&#39;Key&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">file_list</span>

<span class="k">def</span> <span class="nf">write_file</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">bucket</span><span class="p">,</span> <span class="n">content</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">s3_client</span><span class="o">.</span><span class="n">put_object</span><span class="p">(</span><span class="n">Body</span><span class="o">=</span><span class="n">content</span><span class="p">,</span> <span class="n">Key</span><span class="o">=</span><span class="n">file_name</span><span class="p">,</span> <span class="n">Bucket</span><span class="o">=</span><span class="n">bucket</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">ClientError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="kc">True</span>

<span class="k">def</span> <span class="nf">delete_file</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">bucket</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">s3_client</span><span class="o">.</span><span class="n">delete_object</span><span class="p">(</span><span class="n">Key</span><span class="o">=</span><span class="n">file_name</span><span class="p">,</span> <span class="n">Bucket</span><span class="o">=</span><span class="n">bucket</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">ClientError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="kc">True</span>

<span class="k">def</span> <span class="nf">copy_file</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">bucket</span><span class="p">,</span> <span class="n">source_file</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">s3_client</span><span class="o">.</span><span class="n">copy_object</span><span class="p">(</span><span class="n">Key</span><span class="o">=</span><span class="n">file_name</span><span class="p">,</span> <span class="n">Bucket</span><span class="o">=</span><span class="n">bucket</span><span class="p">,</span> <span class="n">CopySource</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">&#39;Bucket&#39;</span><span class="p">:</span> <span class="n">bucket</span><span class="p">,</span>
            <span class="s1">&#39;Key&#39;</span><span class="p">:</span> <span class="n">source_file</span>
        <span class="p">})</span>
    <span class="k">except</span> <span class="n">ClientError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="kc">True</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">copy_folder</span><span class="p">(</span><span class="n">bucket</span><span class="p">,</span> <span class="n">sourcefolder</span><span class="p">,</span> <span class="n">targetfolder</span><span class="p">,</span> <span class="n">deleteSource</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">file_list</span> <span class="o">=</span> <span class="n">list_object</span><span class="p">(</span><span class="n">bucket</span><span class="p">,</span> <span class="n">sourcefolder</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">file_list</span><span class="p">:</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">targetfolder</span><span class="o">+</span><span class="n">obj</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sourcefolder</span><span class="p">):]</span>
        <span class="n">copy_file</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">bucket</span><span class="p">,</span> <span class="n">obj</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">deleteSource</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sourcefolder</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">delete_file</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">bucket</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">BytesIO</span>

<span class="k">def</span> <span class="nf">create_csv</span><span class="p">(</span><span class="n">sourcedf</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">target_bucket</span><span class="p">):</span>
    <span class="n">csv_buffer</span> <span class="o">=</span> <span class="n">BytesIO</span><span class="p">()</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">sourcedf</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span>
    <span class="n">data</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">csv_buffer</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span> <span class="o">=</span> <span class="s1">&#39;utf_8_sig&#39;</span><span class="p">)</span> <span class="c1"># 参数 compression=&#39;gzip&#39; 可以生成压缩文件 filename=&#39;data.csv.gz&#39;</span>
    <span class="n">content</span> <span class="o">=</span> <span class="n">csv_buffer</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span>
    <span class="n">write_file</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">target_bucket</span><span class="p">,</span> <span class="n">content</span><span class="p">)</span>
</code></pre></div>

<h2><span class="caps">SQL</span> <span class="caps">SERVER</span></h2>
<ul>
<li><span class="caps">JDBC</span></li>
</ul>
<p>读取数据库</p>
<div class="highlight"><pre><span></span><code><span class="n">jdbcHostname</span> <span class="o">=</span> <span class="s1">&#39;xxx&#39;</span>
<span class="n">jdbcPort</span> <span class="o">=</span> <span class="s1">&#39;1433&#39;</span>
<span class="n">jdbcDatabase</span> <span class="o">=</span> <span class="s1">&#39;xxx&#39;</span>
<span class="n">properties</span> <span class="o">=</span> <span class="p">{</span>
<span class="s2">&quot;user&quot;</span> <span class="p">:</span> <span class="s1">&#39;xxx&#39;</span><span class="p">,</span>
<span class="s2">&quot;password&quot;</span> <span class="p">:</span> <span class="s1">&#39;xxx&#39;</span> <span class="p">}</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;jdbc:sqlserver://</span><span class="si">{0}</span><span class="s2">:</span><span class="si">{1}</span><span class="s2">;database=</span><span class="si">{2}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">jdbcHostname</span><span class="p">,</span><span class="n">jdbcPort</span><span class="p">,</span><span class="n">jdbcDatabase</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">jdbc</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span><span class="n">table</span><span class="o">=</span><span class="s1">&#39;xxx&#39;</span><span class="p">,</span><span class="n">properties</span> <span class="o">=</span> <span class="n">properties</span><span class="p">))</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">config_table</span> <span class="o">=</span> <span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span>
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;jdbc&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;url&quot;</span><span class="p">,</span> <span class="n">url</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;dbtable&quot;</span><span class="p">,</span> <span class="s1">&#39;xxx&#39;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="p">[</span><span class="s1">&#39;user&#39;</span><span class="p">])</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;password&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="p">[</span><span class="s1">&#39;password&#39;</span><span class="p">])</span>
  <span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">config_table</span><span class="p">)</span>
</code></pre></div>

<p>创建表</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">([</span>
  <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;TableName&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="n">nullable</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span>
  <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;SQLFlag&quot;</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">(),</span> <span class="n">nullable</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span>
<span class="p">])</span>

<span class="n">configList</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s1">&#39;DIM_Calendar&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="p">]</span>

<span class="n">config_df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">configList</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>
<span class="n">config_df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

<p><em>踩坑：StructField无法创建自增字段</em></p>
<div class="highlight"><pre><span></span><code><span class="k">SET</span><span class="w"> </span><span class="n">jdbcURL</span><span class="o">=`</span><span class="n">xxx</span><span class="o">`</span>

<span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="o">&lt;</span><span class="k">Schema_Name</span><span class="o">&gt;</span><span class="p">.</span><span class="o">&lt;</span><span class="k">Table_Name</span><span class="o">&gt;</span>
<span class="w">  </span><span class="k">USING</span><span class="w"> </span><span class="n">JDBC</span>
<span class="k">OPTIONS</span><span class="w"> </span><span class="p">(</span>
<span class="w">  </span><span class="n">url</span><span class="w"> </span><span class="ss">&quot;${hiveconf:jdbcURL}&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">dbtable</span><span class="w"> </span><span class="s1">&#39;xxx&#39;</span><span class="p">,</span>
<span class="w">  </span><span class="k">user</span><span class="w"> </span><span class="s1">&#39;xxx&#39;</span><span class="p">,</span>
<span class="w">  </span><span class="n">password</span><span class="w"> </span><span class="s1">&#39;xxx&#39;</span>
<span class="p">)</span><span class="w"> </span><span class="k">AS</span>
<span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">df_spark</span>
</code></pre></div>

<blockquote>
<p>这样创建的表 location在sql&nbsp;server，不在湖中，湖里不会有对应的文件夹</p>
</blockquote>
<hr>
<h2>Cluster&nbsp;集群</h2>
<p>Cluster&nbsp;type:</p>
<ul>
<li>
<p>All-purpose cluster: can be shared by multiple users and are best for performing ad-hoc analysis, data exploration, or&nbsp;development. </p>
</li>
<li>
<p>Job cluster:  Job clusters terminate when your job ends, reducing resource usage and cost. Once you’ve completed implementing your processing and are ready to operationalize your code, switch to running it on a job&nbsp;cluster.</p>
</li>
</ul>
<p><em>踩坑：<span class="caps">ADF</span> 调用notebook 报错：Failure starting repl. Try detaching and re-attaching the notebook. 此类问题一般发生的原因为Driver node&nbsp;size不足/处于繁忙状态来不及处理请求。</em></p>
<ol>
<li>在ADF activity侧加上了自动重试 retry 次数。（当cmd1成功，cmd2失败，重生会导致cmd1反复执行，所以 <span class="caps">DML</span> 增量数据若要加retry 需要先 delete&nbsp;插入数据，全量数据truncate不回重复）</li>
<li>建议对于生产job任务采用Job cluster，而不是all purpose cluster。 Job cluster有更好的资源隔离，即用即删，成本也更便宜。但是job&nbsp;cluster背后要足量ip，ip不足会导致job直接挂掉无法修复，一般是有1024网段的databricks采用。</li>
</ol>
<p><em>踩坑：IpykernelUtils are causing the conflict and holding the python process. It is since 11.3 which has introduced Ipykernel&nbsp;shells</em></p>
<p>当存在在一个interactive cluster上同时跑多个并行notebooks的情况，IpykernelUtils 会引起冲突并且holding python process, 进而出现无法启动python&nbsp;kernel的错误。</p>
<p>在cluster添加如下spark configuration：
    &#8220;spark.databricks.python.defaultPythonRepl&nbsp;pythonshell&#8221;</p>
<p><em>踩坑：Caused by: org.apache.hadoop.fs.PathIOException: `/[schemaName]/[tableName]/_SUCCESS&#8217;: Input/output error: Parallel access to the create path detected. Failing request to honor single writer&nbsp;semantics</em></p>
<p>限制Spark往HDFS写出数据时生成_SUCCESS文件&nbsp;（未验证）</p>
<div class="highlight"><pre><span></span><code><span class="k">set</span><span class="w"> </span><span class="n">mapreduce</span><span class="p">.</span><span class="n">fileoutputcommitter</span><span class="p">.</span><span class="n">marksuccessfuljobs</span><span class="o">=</span><span class="k">false</span>
</code></pre></div>

<h2>Library</h2>
<p><em>踩坑：Library installation failed due to infra&nbsp;fault</em></p>
<ul>
<li>工作区库&nbsp;workspace-libraries</li>
</ul>
<p>工作区库充当本地存储库，工作区中的所有用户均可使用共享文件夹中的工作区库，而某个用户文件夹中的工作区库仅该用户可用。</p>
<p>可以从工作区库中创建群集安装库，先在群集上安装工作区库，然后才能将其用于笔记本或作业。</p>
<p>先从公共存储库（PyPI 或 Maven）安装需要的库 create library -&gt; PyPI 将 Python Whl&nbsp;下载到本地</p>
<p>再上传下载的包到DBFS create library -&gt; Upload -&gt; Python&nbsp;Whl</p>
<ul>
<li>集群库&nbsp;cluster-libraries</li>
</ul>
<p>群集库可供群集上运行的所有笔记本使用</p>
<p>安装已上传到工作区的工作区库：Install new -&gt;&nbsp;Workspace</p>
<p>https://learn.microsoft.com/zh-cn/azure/databricks/libraries/workspace-libraries</p>
<hr>
<h2>Diagnostic&nbsp;setting</h2>
<p>Azure portal -&gt; Databricks -&gt; Monitoring -&gt; Diagnostic&nbsp;settings</p>
<p>workspace的监控日志，比如谁生成/删除一个token</p>
<h2>Unity Catalog&nbsp;数据治理组件</h2>
<p>功能：
* 治理所有数据资产：数仓，库表，数据湖，文件，机器学习模型，dashboard, notebook
* 数据血缘 Data lineage
* 安全策略
* ABAC权限管理，表级、列级权限控制（<span class="caps">WIP</span>） Centralized metadata and user management / Centralized access controls
* 数据审计 Data access auditing
* 数据共享 Secure data sharing with Delta Sharing
* Data search and&nbsp;discovery</p>
<p>主要数据对象的层次结构 Hierarchy of primary data objects flows:
* Metastore 元存储：元数据的顶级容器，用于管理对数据资产的访问的权限，用户可以查看分配了USAGE数据权限的所有目录。
* Catalog 目录
* Schema 架构/数据库
* Table&nbsp;表/视图</p>
    </div><!-- /.entry-content -->
    <footer class="post-meta">
        <span class="meta-prep">Category:</span>
        <abbr class="category">
            <a href="/category/cloud.html">Cloud</a>
        </abbr>
        <p>
        <span class="meta-prep">Author: </span><span>Yoga</span>
      </p>
    </footer>
    <!-- <section id="respond">
        <div id="disqus_thread">
        <script type="text/javascript">
        var disqus_identifier = "microsoft-azure-databricks.html";
        (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
        </script>
        </div>

    </section> -->
</section>


        </section><!-- #content -->
        <section id="widgets" class="grid col-300 fit" >
            <!--
            <section id="widget-search" class="widget-wrapper widget_search">

                <form id="searchform" action="http://www.google.com/search" method="get">
                    <input id="q" class="field" type="text" placeholder="Search Blog" name="q" ></input>
                    <input id="ie" name="ie" type="hidden" value="utf-8" ></input>
                    <input id="oe" name="oe" type="hidden" value="utf-8" ></input>
                    <input id="channel" name="channel" type="hidden" value="suggest" ></input>
                    <input id="searchsubmit" class="submit" type="submit" value="">
                </form>
            </section>
            -->
            <section id="widget-category" class="widget-wrapper widget_archive">
                <div class="widget-title">
                    Article
                </div>
                <ul>
                        <li>
                          <a href="/category/analytics.html" >Analytics</a>
                        </li>
                        <li>
                          <a href="/category/angular.html" >Angular</a>
                        </li>
                        <li>
                          <a href="/category/backend.html" >Backend</a>
                        </li>
                        <li>
                          <a href="/category/cloud.html" >Cloud</a>
                        </li>
                        <li>
                          <a href="/category/frontend.html" >Frontend</a>
                        </li>
                        <li>
                          <a href="/category/ios.html" >IOS</a>
                        </li>
                        <li>
                          <a href="/category/javascript.html" >Javascript</a>
                        </li>
                        <li>
                          <a href="/category/programming.html" >Programming</a>
                        </li>
                        <li>
                          <a href="/category/project.html" >Project</a>
                        </li>
                        <li>
                          <a href="/category/react.html" >React</a>
                        </li>
                </ul>
            </section>

            <section id="widget-tagcloud" class="widget-wrapper widget_archive">
                <div class="widget-title">
                    Tagcloud
                </div>
                <div>
                        <span><a href="/tag/dva.html">DVA</a></span>
                        <span><a href="/tag/azure.html">Azure</a></span>
                        <span><a href="/tag/security.html">Security</a></span>
                        <span><a href="/tag/microsoft.html">Microsoft</a></span>
                        <span><a href="/tag/java.html">Java</a></span>
                        <span><a href="/tag/express.html">Express</a></span>
                        <span><a href="/tag/architecture.html">Architecture</a></span>
                        <span><a href="/tag/cicd.html">CI/CD</a></span>
                        <span><a href="/tag/database.html">database</a></span>
                        <span><a href="/tag/ml.html">ML</a></span>
                        <span><a href="/tag/aws.html">AWS</a></span>
                        <span><a href="/tag/etl.html">ETL</a></span>
                        <span><a href="/tag/nest.html">nest</a></span>
                        <span><a href="/tag/sql.html">sql</a></span>
                        <span><a href="/tag/antv.html">AntV</a></span>
                        <span><a href="/tag/next.html">Next</a></span>
                        <span><a href="/tag/deep-learning.html">Deep Learning</a></span>
                        <span><a href="/tag/flutter.html">Flutter</a></span>
                        <span><a href="/tag/typescript.html">TypeScript</a></span>
                        <span><a href="/tag/angular.html">Angular</a></span>
                        <span><a href="/tag/devtools.html">DevTools</a></span>
                        <span><a href="/tag/egg.html">egg</a></span>
                        <span><a href="/tag/tableau.html">Tableau</a></span>
                        <span><a href="/tag/sap.html">SAP</a></span>
                        <span><a href="/tag/token.html">Token</a></span>
                        <span><a href="/tag/regexp.html">Regexp</a></span>
                        <span><a href="/tag/unit-test.html">Unit test</a></span>
                        <span><a href="/tag/nginx.html">Nginx</a></span>
                        <span><a href="/tag/nodejs.html">nodeJS</a></span>
                        <span><a href="/tag/sails.html">sails</a></span>
                        <span><a href="/tag/wechat.html">wechat</a></span>
                        <span><a href="/tag/jmeter.html">Jmeter</a></span>
                        <span><a href="/tag/html2canvas.html">HTML2Canvas</a></span>
                        <span><a href="/tag/swift.html">Swift</a></span>
                        <span><a href="/tag/jenkins.html">Jenkins</a></span>
                        <span><a href="/tag/js.html">JS</a></span>
                        <span><a href="/tag/event.html">event</a></span>
                        <span><a href="/tag/gtm.html">GTM</a></span>
                        <span><a href="/tag/algorithm.html">Algorithm</a></span>
                        <span><a href="/tag/echarts.html">Echarts</a></span>
                        <span><a href="/tag/react-admin.html">React-Admin</a></span>
                        <span><a href="/tag/rest.html">Rest</a></span>
                        <span><a href="/tag/react.html">React</a></span>
                        <span><a href="/tag/hook.html">hook</a></span>
                        <span><a href="/tag/flux.html">Flux</a></span>
                        <span><a href="/tag/redux.html">Redux</a></span>
                        <span><a href="/tag/es6.html">ES6</a></span>
                        <span><a href="/tag/route.html">Route</a></span>
                        <span><a href="/tag/component.html">Component</a></span>
                        <span><a href="/tag/ref.html">Ref</a></span>
                        <span><a href="/tag/ajax.html">AJAX</a></span>
                        <span><a href="/tag/form.html">Form</a></span>
                        <span><a href="/tag/jsx.html">JSX</a></span>
                        <span><a href="/tag/virtual-dom.html">Virtual Dom</a></span>
                        <span><a href="/tag/javascript.html">Javascript</a></span>
                        <span><a href="/tag/css.html">CSS</a></span>
                        <span><a href="/tag/design-pattern.html">design pattern</a></span>
                </div>
            </section>


            <section id="widget-links" class="widget-wrapper widget_archive">
                <div class="widget-title">
                    Links
                </div>
                <ul>
                        <li><a href="https://github.com/yogagii">Github</a></li>
                        <li><a href="https://preview-static.clewm.net/cli/view-doc/view.html?url=https%3A%2F%2Fncstatic.clewm.net%2Frsrc%2F2021%2F0510%2F20%2F013c587ff42ef5f36ccb923c9d7a3765.pdf">UI/UX/Frontend/Game Design</a></li>
                        <li><a href="https://preview-static.clewm.net/cli/view-doc/view.html?url=https%3A%2F%2Fncstatic.clewm.net%2Frsrc%2F2021%2F0510%2F19%2F64852862e888e4db944b06eea147d035.pdf">Industrial Design Portfolio</a></li>
                </ul>
            </section>
            
        </section><!-- widgets -->
    </section><!-- /#wrapper -->
    <footer id="footer" class="clearfix"><section class="footer-wrapper">
        <div class="grid col-940" >
            <div class="grid col-540"></div>
            <div class="grid col-380 fit" >
                <ul class="social-icons">
                    <!-- TO BE CONTINUED -->
                </ul>
            </div>
        </div>

        <div class="grid col-300 copyright" >
            <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/" rel="license">
                <img src="http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" style="border-width:0" alt="知识共享许可协议"></img>
            </a>
        </div>
        <div class="grid col-300 ">

        </div>
        <div class="grid col-300 fit powered">
            Powered by <a href="http://getpelican.com/">Pelican</a> <br />
            which takes great advantage of <a href="http://python.org">Python</a>
        </div>
    </section></footer>
</div>
</body>
</html>