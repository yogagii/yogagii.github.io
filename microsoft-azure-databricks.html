<!--
 * @Author: your name
 * @Date: 2013-11-02 09:09:18
 * @LastEditTime : 2019-12-29 22:05:43
 * @LastEditors  : Please set LastEditors
 * @Description: In User Settings Edit
 * @FilePath: /YogaBlog/pelican-themes/Responsive-Pelican/templates/article.html
 -->
<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
    <title>Frontend Learning Book</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0">
    <link rel="stylesheet" id="responsive-style-css"  href='/theme/css/style.css' type="text/css" media="all" />
    <link rel="stylesheet" id="responsive-style-css"  href='/theme/css/highlight.css' type="text/css" media="all" />
    
</head>

<body id="index" class="blog">
<div id="container" class="hfeed">
    <header id="header" >
        <div id="logo">
          <h1>
            <!-- <img src="/theme/image/default-logo.png" width="300" height="100" alt="小铱的故事" /> -->
            Frontend Learning Book
          </h1>
        </div> <!-- /#logo-->
        <nav id="menu" class="main-nav"><ul class="menu">
            <li  class="active"><a href="/category/javascript.html">Javascript</a></li>
            <li  class="active"><a href="/category/react.html">React</a></li>
            <li  class="active"><a href="/category/ios.html">IOS</a></li>
            <li  class="active"><a href="/category/frontend.html">Frontend</a></li>
            <li  class="active"><a href="/category/analytics.html">Analytics</a></li>
            <li  class="active"><a href="/category/programming.html">Programming</a></li>
            <li  class="active"><a href="/category/project.html">Project</a></li>
            <li  class="active"><a href="/category/backend.html">Backend</a></li>
            <li  class="active"><a href="/category/angular.html">Angular</a></li>
            <li  class="active"><a href="/category/cloud.html">Cloud</a></li>

        </ul></nav><!-- /#menu -->
    </header>
    <section id="wrapper" class="clearfix">
        <section id="content" class="grid col-620" >
                <section class="breadcrumb-list">
<a href="">Blog</a> ›<a href="category/cloud.html">Cloud</a> ›Microsoft Azure&nbsp;Databricks
                </section>


<section id="post" class="post hentry">
    <header>
    <h2 class="post-title" >Microsoft Azure&nbsp;Databricks</h2>
    
    <div class="post-meta">
        <span class="meta-prep">Post in</span>
        <abbr class="date" title="2022-11-22T00:00:00+08:00"> 
            <a href="/archive/2022/11/index.html">二 22 十一月 2022 </a>
        </abbr>
        <span class="meta-prep"> |Tags</span>
                <a href="/tag/azure.html">Azure</a>
                <a href="/tag/etl.html">ETL</a>
        <!-- TOBE COMMENTS -->
    </div>
    </header>
    <div class="post-entry">
        <p><span class="caps">ETL</span>: Extract, Transform and Load&nbsp;数据仓库技术</p>
<p>databricks是使用Apache&nbsp;Spark™的原始创建者提供的Databricks统一分析平台。它集成了Spark环境支持Scala、python、R语言进行开发。</p>
<p>adb-xxx.azuredatabricks.net</p>
<p>Workspace -&gt; Users (your own folder) -&gt; 右键import -&gt; .dbc&nbsp;file</p>
<p>-&gt; Create -&gt; Notebook -&gt; Default language:&nbsp;python</p>
<p>jobs -&gt; start&nbsp;cluster</p>
<h2>调用notebook</h2>
<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">run</span> <span class="o">/</span><span class="n">_POC_QA_SC_DataCenter</span><span class="o">/</span><span class="n">Dayu</span><span class="o">-</span><span class="n">connect</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">datalake</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">dbutils</span><span class="o">.</span><span class="n">notebook</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;/_POC_QA_SC_DataCenter/Dayu-connect-to-datalake_Func&quot;</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;argument&quot;</span><span class="p">:</span> <span class="s2">&quot;data&quot;</span><span class="p">})</span>
</code></pre></div>

<ul>
<li>优势：可传参，可调用多个笔记本</li>
<li>缺点：启动新作业，变量不存在</li>
</ul>
<h2>Output</h2>
<div class="highlight"><pre><span></span><code><span class="n">dbutils</span><span class="o">.</span><span class="n">notebook</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>

<p><span class="caps">ADF</span>&nbsp;读取output：@activity(&#8216;Notebook&#8217;).output</p>
<h2>文件操作</h2>
<ul>
<li>dbutils</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="s2">&quot;abfss://container@blob.xxx.cn/folder/&quot;</span><span class="p">)</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">rm</span><span class="p">(</span><span class="s2">&quot;abfss://container@blob.xxx.cn/folder/filename&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">mkdirs</span><span class="p">(</span><span class="n">TempPath</span><span class="p">)</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">cp</span><span class="p">(</span><span class="n">SapPath</span><span class="o">+</span><span class="n">FileName</span><span class="p">,</span> <span class="n">TempPath</span><span class="p">)</span>
</code></pre></div>

<p><em>踩坑：若要跟新表结构，需将存表的文件夹删除</em></p>
<ul>
<li>获取文件名</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span> \
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;abfss://container@blob.xxx.cn/folder/filename_*.txt&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">,</span> <span class="s2">&quot;_metadata&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;df_spark&quot;</span><span class="p">)</span>
<span class="n">df1</span><span class="o">=</span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;select distinct _metadata.file_name as filename from (select * from df_spark order by _metadata) a&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">30</span><span class="p">):</span>
    <span class="n">filename</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">df1</span><span class="o">.</span><span class="n">collect</span><span class="p">()[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div>

<p><em>踩坑：xlsx文件也只能用 .format(&#8216;csv&#8217;) 不能&nbsp;.format(&#8220;com.crealytics.spark.excel&#8221;)</em></p>
<ul>
<li>os</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="nf">%sh</span><span class="w"> </span><span class="n">ls</span><span class="w"> </span><span class="o">/</span><span class="w"></span>
</code></pre></div>

<ul>
<li>azure-storage-file-datalake</li>
</ul>
<div class="highlight"><pre><span></span><code>pip install azure-storage-file-datalake
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">uuid</span><span class="o">,</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">azure.storage.filedatalake</span> <span class="kn">import</span> <span class="n">DataLakeServiceClient</span>
<span class="kn">from</span> <span class="nn">azure.core._match_conditions</span> <span class="kn">import</span> <span class="n">MatchConditions</span>
<span class="kn">from</span> <span class="nn">azure.storage.filedatalake._models</span> <span class="kn">import</span> <span class="n">ContentSettings</span>

<span class="k">def</span> <span class="nf">initialize_storage_account</span><span class="p">():</span>
    <span class="k">try</span><span class="p">:</span>  
        <span class="k">global</span> <span class="n">service_client</span>
        <span class="n">credential</span> <span class="o">=</span> <span class="n">ClientSecretCredential</span><span class="p">(</span><span class="n">tenant_id</span><span class="p">,</span> <span class="n">client_id</span><span class="p">,</span> <span class="n">client_secret</span><span class="p">)</span>
        <span class="n">service_client</span> <span class="o">=</span> <span class="n">DataLakeServiceClient</span><span class="p">(</span><span class="n">account_url</span><span class="o">=</span><span class="n">account_url</span><span class="p">,</span> <span class="n">credential</span><span class="o">=</span><span class="n">credential</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">list_directory</span><span class="p">(</span><span class="n">container</span><span class="o">=</span><span class="s2">&quot;raw&quot;</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s2">&quot;example_folder&quot;</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">file_system_client</span> <span class="o">=</span> <span class="n">service_client</span><span class="o">.</span><span class="n">get_file_system_client</span><span class="p">(</span><span class="n">file_system</span><span class="o">=</span><span class="n">container</span><span class="p">)</span>
        <span class="n">paths</span> <span class="o">=</span> <span class="n">file_system_client</span><span class="o">.</span><span class="n">get_paths</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">folder</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
     <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_directory</span><span class="p">(</span><span class="n">container</span><span class="o">=</span><span class="s2">&quot;raw&quot;</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s2">&quot;example_folder&quot;</span><span class="p">):</span>
    <span class="n">file_system_client</span> <span class="o">=</span> <span class="n">service_client</span><span class="o">.</span><span class="n">get_file_system_client</span><span class="p">(</span><span class="n">file_system</span><span class="o">=</span><span class="n">container</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">file_system_client</span><span class="o">.</span><span class="n">create_directory</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">delete_file</span><span class="p">(</span><span class="n">container</span><span class="o">=</span><span class="s2">&quot;raw&quot;</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="s2">&quot;example_folder/example.xlsx&quot;</span><span class="p">):</span>
    <span class="n">file_system_client</span> <span class="o">=</span> <span class="n">service_client</span><span class="o">.</span><span class="n">get_file_system_client</span><span class="p">(</span><span class="n">file_system</span><span class="o">=</span><span class="n">container</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">file_system_client</span><span class="o">.</span><span class="n">delete_file</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">delete_directory</span><span class="p">(</span><span class="n">container</span><span class="o">=</span><span class="s2">&quot;raw&quot;</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s2">&quot;example_folder&quot;</span><span class="p">):</span>
    <span class="n">file_system_client</span> <span class="o">=</span> <span class="n">service_client</span><span class="o">.</span><span class="n">get_file_system_client</span><span class="p">(</span><span class="n">file_system</span><span class="o">=</span><span class="n">container</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">file_system_client</span><span class="o">.</span><span class="n">delete_directory</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span>
</code></pre></div>

<h2>文件读写</h2>
<ul>
<li><span class="caps">CSV</span></li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">df_csv</span><span class="o">=</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;encoding&quot;</span><span class="p">,</span><span class="s2">&quot;GBK&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;abfss://container@blob.xxx.cn/folder/filename.csv&quot;</span><span class="p">);</span>
<span class="n">display</span><span class="p">(</span><span class="n">df_csv</span><span class="p">)</span>
<span class="c1"># GBK解决中文乱码</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1"># CSV不需要header</span>
<span class="n">df_csv</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="o">&lt;</span><span class="n">target_file</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span> <span class="o">=</span> <span class="s1">&#39;utf_8_sig&#39;</span><span class="p">)</span>
</code></pre></div>

<p><em>踩坑：encoding为GBK时，excel里将&#8221;创作语言和校对&#8221;设置英文首选，会出现中文乱码全是？情况</em></p>
<ul>
<li><span class="caps">TXT</span></li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">df_txt</span><span class="o">=</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">sourcefile</span><span class="p">);</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">df_txt</span><span class="o">.</span><span class="n">coalesce</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;s3://&lt;bucket&gt;/&lt;folder&gt;/filename&quot;</span><span class="p">)</span>
</code></pre></div>

<p><em>踩坑：coalesce只会确保产生一个文件，仍会生成以filename命名的文件夹，文件夹下有以part加数字命名的txt文件(以及_SUCCESS, _committed,&nbsp;_started文件)</em></p>
<div class="highlight"><pre><span></span><code><span class="c1"># 解决txt文件每一行有引号</span>
<span class="n">df_txt</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="o">&lt;</span><span class="n">target_file</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">quoting</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">quotechar</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
</code></pre></div>

<ul>
<li>Excel</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="c1"># header必传项, maxRowsInMemory解决文件过大&gt;10mb</span>
<span class="n">df_excel</span><span class="o">=</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;com.crealytics.spark.excel&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span><span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;maxRowsInMemory&quot;</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">sourcefile</span><span class="p">);</span>
</code></pre></div>

<p>csv是通过spark读的，excel是spark底层hadoop读的，libraries里安装com.crealytics:spark-excel</p>
<div class="highlight"><pre><span></span><code><span class="n">pip</span> <span class="n">install</span> <span class="n">openpyxl</span>

<span class="c1"># excel文件得保留header</span>
<span class="n">df_excel</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="o">&lt;</span><span class="n">target_file</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</code></pre></div>

<ul>
<li><span class="caps">JSON</span></li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">json</span><span class="p">.</span><span class="o">`</span><span class="n">abfss</span><span class="p">:</span><span class="o">//</span><span class="n">container</span><span class="o">@</span><span class="nb">blob</span><span class="p">.</span><span class="n">xxx</span><span class="p">.</span><span class="n">cn</span><span class="o">/</span><span class="n">folder</span><span class="o">/</span><span class="n">filename</span><span class="o">`</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">df_DateLake</span><span class="o">=</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;abfss://container@blob.xxx.cn/folder/filename.json&quot;</span><span class="p">);</span>
</code></pre></div>

<ul>
<li>Parquet</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">delta</span><span class="p">.</span><span class="o">`</span><span class="n">abfss</span><span class="p">:</span><span class="o">//</span><span class="n">container</span><span class="o">@</span><span class="nb">blob</span><span class="p">.</span><span class="n">xxx</span><span class="p">.</span><span class="n">cn</span><span class="o">/</span><span class="n">folder</span><span class="o">/</span><span class="n">filename</span><span class="o">`</span>
</code></pre></div>

<h2>Delta&nbsp;Table</h2>
<p>Delta Lake 是经过优化的存储层，它使用基于文件的事务日志扩展了 Parquet 数据文件，可以处理 <span class="caps">ACID</span> 事务和可缩放的元数据。Delta Lake 是 Azure Databricks 上所有操作的默认存储格式。 除非另行指定，否则 Azure Databricks 上的所有表都是 Delta&nbsp;表。</p>
<blockquote>
<p><span class="caps">ACID</span>:&nbsp;原子性、一致性、隔离性、持久性</p>
</blockquote>
<p>Delta Lake 特性：
* 支持ACID事务
* 可扩展的元数据处理
* 统一的流、批处理API接口
* 更新、删除数据，实时读写（读是读当前的最新快照）
* 数据版本控制，根据需要查看历史数据快照，可回滚数据
*&nbsp;自动处理schema变化，可修改表结构</p>
<p>可以使用 <span class="caps">DESCRIBE</span> <span class="caps">DETAIL</span> 检索有关 Delta&nbsp;表的详细信息</p>
<div class="highlight"><pre><span></span><code><span class="k">DESCRIBE</span> <span class="n">DETAIL</span> <span class="n">eventsTable</span>
</code></pre></div>

<p>返回对表的每次写入的出处信息，包括操作、用户等。 表历史记录会保留 30&nbsp;天。即使parquet文件被vacuum，历史也会保留。</p>
<div class="highlight"><pre><span></span><code><span class="k">DESCRIBE</span> <span class="n">HISTORY</span> <span class="n">eventsTable</span>
</code></pre></div>

<p>delta表的schema中，字段名的小写不能相同，delta&nbsp;lake区分大小写，但保存时不敏感，而parquet保存时是大小写敏感的</p>
<p>delta表是一个目录，表的根目录除了表数据外，有一个_delta_log目录，用来存放事务日志；事务日志记录了从最初的delta表开始的所有commit事件，每个commit形成一个json文件，文件名是严格递增的，文件名就是版本号。每10个json合并成一个parquet格式的checkpoint文件，记录之前所有的commit。spark读的时候会自动跳到最新的checkpoint，然后再读之后的json；</p>
<p>当多个用户同时写数据时，都是生成一个新版本的数据文件，用互斥锁来决定顺序，拿到锁的，按顺序生成下一个版本的数据文件，然后释放锁，后来的在之前数据的基础上执行他的commit，生成一个新版本的数据。</p>
<p>truncate table不会释放存储空间：Delta Lake 删除操作后，旧数据文件不会被完全删除，仍保留在磁盘上，但在 Delta Lake 事务日志中记录为“tombstoned”（不再是活动表的一部分）。可以通过time travel回到表的早期版本，如果要删除超过某个时间段的文件，可以使用 <span class="caps">VACUUM</span> 以递归方式清空与 Spark 表关联的目录，并删除超过保留期阈值的未提交文件。 默认阈值为 7&nbsp;天。</p>
<div class="highlight"><pre><span></span><code><span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="k">table_name</span> <span class="k">VERSION</span> <span class="k">AS</span> <span class="k">OF</span> <span class="mi">100</span>
<span class="c1">-- 回滚</span>
<span class="n">RESTORE</span> <span class="p">[</span> <span class="k">TABLE</span> <span class="p">]</span> <span class="k">table_name</span> <span class="p">[</span> <span class="k">TO</span> <span class="p">]</span> <span class="n">time_travel_version</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1">-- 清理</span>
<span class="k">VACUUM</span> <span class="k">table_name</span> <span class="p">[</span><span class="n">RETAIN</span> <span class="n">num</span> <span class="n">HOURS</span><span class="p">]</span> <span class="p">[</span><span class="n">DRY</span> <span class="n">RUN</span><span class="p">]</span>
</code></pre></div>

<p>Vacuum 后可在 Storage Explorer 对应表的文件夹下 Folder Statictis 看到 Active blob明显减少，但是当 Storage Account 启用了软删除 Data protection -&gt; Enable soft delete for blobs / containers 时，Total&nbsp;数量不会减少，在软删除有效期内删除的文件可以在portal上看到并还原，有效期过后会永久删除</p>
<p>Delta lake 优点：
* 实时查询，支持ACID功能，保证了数据流入和查询的隔离性，不会产生脏数据。
* Delta支持数据的删除或更新，数据实时同步 <span class="caps">CDC</span>：使用Delta merge功能，启动流作业，实时将上游的数据通过merge更新到Delta Lake中。
* 数据质量控制：借助于Delta&nbsp;Schema校验功能，在数据导入时剔除异常数据，或者对异常数据做进一步处理。</p>
<p>Delta lake 缺点：
* 更新操作很重，更新一条数据和更新一批数据的成本可能是一样的，所以不适合一条条的更新数据
* 更新数据的方式是新增文件，会造成文件数量过多，需要清理历史版本的数据
*&nbsp;乐观锁的并发能力较差，更适合写少读多的场景</p>
<p><em>踩坑：用 <span class="caps">ADF</span> 将.parquet文件存储到sql server时，delta table格式会保留下全部数据文件，将需要转存sql server的表（dm和dim，需要update的表不行）改为 <span class="caps">USING</span> parquet，parquet&nbsp;表可每次truncate后全量更新，需保证字段格式严格按照ddl中定义的格式.</em></p>
<p><strong><span class="caps">DCL</span></strong></p>
<ul>
<li>blob&nbsp;存储文件系统的访问权限</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">GRANT</span> <span class="k">SELECT</span><span class="p">,</span> <span class="k">MODIFY</span> <span class="k">ON</span> <span class="k">ANY</span> <span class="n">FILE</span> <span class="k">TO</span> <span class="o">`&lt;</span><span class="k">user</span><span class="o">&gt;@&lt;</span><span class="k">domain</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;`</span> <span class="c1">--</span>
</code></pre></div>

<ul>
<li>schema&nbsp;访问权限</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">SHOW</span> <span class="n">GRANTS</span> <span class="k">ON</span> <span class="k">SCHEMA</span> <span class="o">&lt;</span><span class="n">SCHEMANAME</span><span class="o">&gt;</span>

<span class="k">GRANT</span> <span class="k">USAGE</span><span class="p">,</span> <span class="k">SELECT</span><span class="p">,</span> <span class="k">CREATE</span><span class="p">,</span> <span class="n">READ_METADATA</span><span class="p">,</span> <span class="k">MODIFY</span> <span class="k">ON</span> <span class="k">SCHEMA</span> <span class="o">&lt;</span><span class="n">SCHEMANAME</span><span class="o">&gt;</span> <span class="k">TO</span> <span class="o">`&lt;</span><span class="k">user</span><span class="o">&gt;@&lt;</span><span class="k">domain</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;`</span>
</code></pre></div>

<ul>
<li>table&nbsp;访问权限</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="o">&lt;</span><span class="n">TABLENAME</span><span class="o">&gt;</span> <span class="k">OWNER</span> <span class="k">TO</span> <span class="o">`&lt;</span><span class="k">user</span><span class="o">&gt;@&lt;</span><span class="k">domain</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;`</span>
<span class="k">GRANT</span> <span class="k">SELECT</span><span class="p">,</span> <span class="n">READ_METADATA</span> <span class="k">ON</span> <span class="k">TABLE</span> <span class="o">&lt;</span><span class="n">TABLENAME</span><span class="o">&gt;</span> <span class="k">TO</span> <span class="o">`&lt;</span><span class="k">user</span><span class="o">&gt;@&lt;</span><span class="k">domain</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;`</span>

<span class="k">DESCRIBE</span> <span class="p">[</span><span class="n">EXTENDED</span><span class="p">]</span> <span class="o">&lt;</span><span class="n">TABLENAME</span><span class="o">&gt;</span> <span class="c1">--表的基本元数据信息</span>

<span class="k">SHOW</span> <span class="n">GRANTS</span> <span class="k">on</span> <span class="k">TABLE</span> <span class="o">&lt;</span><span class="n">TABLENAME</span><span class="o">&gt;</span> <span class="c1">--表的权限信息</span>
<span class="k">SHOW</span> <span class="n">GRANTS</span> <span class="o">`&lt;</span><span class="k">user</span><span class="o">&gt;@&lt;</span><span class="k">domain</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;`</span> <span class="k">on</span> <span class="k">TABLE</span> <span class="o">&lt;</span><span class="n">TABLENAME</span><span class="o">&gt;</span>
</code></pre></div>

<p><strong><span class="caps">DDL</span></strong></p>
<ul>
<li>创建SCHEMA</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">CREATE</span> <span class="k">SCHEMA</span> <span class="n">example_schema</span>
<span class="k">LOCATION</span> <span class="s1">&#39;dbfs:/mnt/azrzdbicinmtdpadlsqa/{container}/{example_schema}&#39;</span>
</code></pre></div>

<ul>
<li>创建TABLE</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">drop</span> <span class="k">table</span> <span class="k">if</span> <span class="k">exists</span> <span class="n">STG</span><span class="p">.</span><span class="n">TableName</span><span class="p">;</span>
<span class="k">create</span> <span class="k">table</span> <span class="n">STG</span><span class="p">.</span><span class="n">TableName</span> 
<span class="p">(</span>
<span class="o">`</span><span class="n">Field1</span><span class="o">`</span> <span class="n">string</span><span class="p">,</span>
<span class="o">`</span><span class="n">Field2</span><span class="o">`</span> <span class="nb">INT</span><span class="p">,</span>
<span class="o">`</span><span class="n">InsertTime</span><span class="o">`</span> <span class="k">timestamp</span><span class="p">)</span>
<span class="k">USING</span> <span class="n">delta</span> 
<span class="k">LOCATION</span> <span class="ss">&quot;abfss://container@blob.xxx.cn/folder/STG/TableName&quot;</span><span class="p">;</span>
</code></pre></div>

<p>如果省略 <span class="caps">USING</span>，则默认值为 <span class="caps">DELTA</span>。</p>
<p>对于除 <span class="caps">DELTA</span> 之外的任何 data_source，还必须指定 <span class="caps">LOCATION</span>，除非catalog为&nbsp;hive_metastore。</p>
<p>设置湖地址</p>
<div class="highlight"><pre><span></span><code><span class="k">set</span> <span class="n">Address</span><span class="o">=</span><span class="n">abfss</span><span class="p">:</span><span class="o">//</span><span class="n">container</span><span class="o">@</span><span class="nb">blob</span><span class="p">.</span><span class="n">xxx</span><span class="p">.</span><span class="n">cn</span><span class="p">;</span>
<span class="p">...</span>
<span class="k">LOCATION</span> <span class="ss">&quot;${hiveconf:Address}/folder/CSTG/TableName&quot;</span><span class="p">;</span>
</code></pre></div>

<p>已创建SCHEMA后不需要Location</p>
<div class="highlight"><pre><span></span><code><span class="c1">-- 加上comment会更好</span>
<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="k">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">example_schema</span><span class="p">.</span><span class="n">example_table</span>
<span class="p">(</span>
 <span class="n">col1</span> <span class="n">STRING</span> <span class="k">COMMENT</span> <span class="s1">&#39;col1_comment&#39;</span>
<span class="p">)</span>
<span class="k">using</span> <span class="n">delta</span>
<span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">insertDate</span><span class="p">)</span>
</code></pre></div>

<ul>
<li>克隆TABLE</li>
</ul>
<blockquote>
<p><span class="caps">SHALLOW</span> <span class="caps">CLONE</span>: 浅表克隆不会将数据文件复制到克隆目标。 表元数据等效于源。 创建这些克隆的成本较低。
</br><span class="caps">DEEP</span> <span class="caps">CLONE</span>:&nbsp;深层克隆还会将源表数据复制到克隆目标。它还会克隆流元数据。</p>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">CREATE</span> <span class="k">OR</span> <span class="k">REPLACE</span> <span class="k">TABLE</span> <span class="o">&lt;</span><span class="k">SCHEMA</span><span class="o">&gt;</span><span class="p">.</span><span class="o">&lt;</span><span class="n">TABLENAME</span><span class="o">&gt;</span> <span class="n">DEEP</span> <span class="n">CLONE</span> <span class="o">&lt;</span><span class="k">SCHEMA</span><span class="o">&gt;</span><span class="p">.</span><span class="o">&lt;</span><span class="n">TABLENAME</span><span class="o">&gt;</span><span class="p">;</span>
</code></pre></div>

<p><strong><span class="caps">DML</span></strong></p>
<ul>
<li>Insert Table: <span class="caps">CSV</span>/<span class="caps">EXCEL</span> (<span class="caps">RAW</span> -&gt; <span class="caps">STG</span>)</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">python</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="n">ManuPath</span><span class="o">=</span><span class="s2">&quot;abfss://container@blob.xxx.cn/folder/RawZone/MANU/&quot;</span>

<span class="k">def</span> <span class="nf">sliceErrorMsg</span><span class="p">(</span><span class="n">msg</span><span class="p">):</span>
    <span class="n">FailReaon</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">FailReaon</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;;&#39;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">FailReaon</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">FailReaon</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;;&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&#39;&quot;</span><span class="p">,</span> <span class="s2">&quot;`&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">FailReaon</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">FailReaon</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">FailReaon</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&#39;&quot;</span><span class="p">,</span> <span class="s2">&quot;`&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">FailReaon</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">30</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&#39;&quot;</span><span class="p">,</span> <span class="s2">&quot;`&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">insertTable</span><span class="p">(</span><span class="n">FileName</span><span class="p">,</span> <span class="n">LandingTableName</span><span class="p">,</span> <span class="n">TableColumn</span><span class="p">,</span> <span class="n">ExcelTitle</span><span class="p">,</span> <span class="n">SaveDay</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">Path</span><span class="o">=</span><span class="n">ManuPath</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">fileFormat</span> <span class="o">=</span> <span class="s1">&#39;csv&#39;</span> <span class="k">if</span> <span class="s1">&#39;csv&#39;</span> <span class="ow">in</span> <span class="n">FileName</span> <span class="k">else</span> <span class="s1">&#39;com.crealytics.spark.excel&#39;</span><span class="p">;</span>
        <span class="n">df_DateLake</span><span class="o">=</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fileFormat</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span><span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">Path</span><span class="o">+</span><span class="n">FileName</span><span class="p">);</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; insert into STG.TableReadLog select &#39;</span><span class="si">{</span><span class="n">LandingTableName</span><span class="si">}</span><span class="s2">&#39;,current_date(),now(),&#39;Not found </span><span class="si">{</span><span class="n">FileName</span><span class="si">}</span><span class="s2">&#39;,null;&quot;</span><span class="p">);</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">df_DateLake</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;df_spark&quot;</span><span class="p">);</span>
        <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;delete from </span><span class="si">{</span><span class="n">LandingTableName</span><span class="si">}</span><span class="s2"> where InsertTime&lt;date_sub(now(), </span><span class="si">{</span><span class="n">SaveDay</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">);</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;insert into </span><span class="si">{</span><span class="n">LandingTableName</span><span class="si">}</span><span class="s2">(</span><span class="si">{</span><span class="n">TableColumn</span><span class="si">}</span><span class="s2">) select </span><span class="si">{</span><span class="n">ExcelTitle</span><span class="si">}</span><span class="s2">,now() InsertTime from df_spark;&quot;</span><span class="p">);</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">FailReaon</span><span class="p">:</span>
            <span class="n">FailReaon</span><span class="o">=</span><span class="n">sliceErrorMsg</span><span class="p">(</span><span class="n">FailReaon</span><span class="p">);</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">FailReaon</span><span class="p">);</span>
            <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;insert into STG.TableReadLog select &#39;</span><span class="si">{</span><span class="n">LandingTableName</span><span class="si">}</span><span class="s2">&#39;,current_date(),now(),&#39;</span><span class="si">{</span><span class="n">FailReaon</span><span class="si">}</span><span class="s2">&#39;,null;&quot;</span><span class="p">);</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;insert into STG.TableWriteLog select &#39;</span><span class="si">{</span><span class="n">LandingTableName</span><span class="si">}</span><span class="s2">&#39;,current_date(),now(),null;&quot;</span><span class="p">);</span>
</code></pre></div>

<ul>
<li>增量</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">INSERT</span> <span class="k">INTO</span> <span class="o">&lt;</span><span class="n">CSTG_SCHEMA</span><span class="o">&gt;&lt;</span><span class="k">TABLE</span><span class="o">&gt;</span> <span class="p">(</span><span class="o">&lt;</span><span class="n">columns</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">InsertTime</span><span class="p">)</span>
<span class="k">SELECT</span> <span class="o">&lt;</span><span class="n">columns</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">NOW</span><span class="p">()</span> <span class="k">FROM</span> <span class="o">&lt;</span><span class="n">STG_SCHEMA</span><span class="o">&gt;</span><span class="p">.</span><span class="o">&lt;</span><span class="k">TABLE</span><span class="o">&gt;</span> <span class="k">WHERE</span> <span class="n">InsertTime</span><span class="o">&gt;</span><span class="k">Current_Date</span><span class="p">();</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">merge</span> <span class="k">into</span> <span class="o">&lt;</span><span class="n">CSTG_SCHEMA</span><span class="o">&gt;&lt;</span><span class="k">TABLE</span><span class="o">&gt;</span> <span class="n">a</span>
<span class="k">using</span> <span class="o">&lt;</span><span class="n">STG_SCHEMA</span><span class="o">&gt;</span><span class="p">.</span><span class="o">&lt;</span><span class="k">TABLE</span><span class="o">&gt;</span> <span class="n">b</span>
    <span class="k">on</span> <span class="n">a</span><span class="p">.</span><span class="n">id</span><span class="o">=</span><span class="n">b</span><span class="p">.</span><span class="n">id</span> <span class="k">and</span> <span class="n">a</span><span class="p">.</span><span class="n">insertDate</span><span class="o">=</span><span class="n">b</span><span class="p">.</span><span class="n">insertDate</span> <span class="c1">-- 同一天内数据更新不会覆盖</span>
<span class="k">when</span> <span class="k">not</span> <span class="n">matched</span> <span class="k">then</span> <span class="k">insert</span> 
<span class="p">(</span><span class="o">&lt;</span><span class="n">columns</span><span class="o">&gt;</span><span class="p">,</span><span class="n">insertDate</span><span class="p">)</span>
<span class="k">values</span><span class="p">(</span><span class="o">&lt;</span><span class="n">columns</span><span class="o">&gt;</span><span class="p">)</span>
</code></pre></div>

<ul>
<li>容错性增量</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">DELETE</span> <span class="k">FROM</span> <span class="o">&lt;</span><span class="n">CSTG_SCHEMA</span><span class="o">&gt;&lt;</span><span class="k">TABLE</span><span class="o">&gt;</span> <span class="n">A</span> <span class="k">WHERE</span> <span class="k">EXISTS</span> <span class="p">(</span><span class="k">SELECT</span> <span class="k">key</span> <span class="k">FROM</span> <span class="o">&lt;</span><span class="n">STG_SCHEMA</span><span class="o">&gt;&lt;</span><span class="k">TABLE</span><span class="o">&gt;</span> <span class="n">B</span> <span class="k">WHERE</span> <span class="n">A</span><span class="p">.</span><span class="k">key</span><span class="o">=</span><span class="n">B</span><span class="p">.</span><span class="k">key</span> <span class="k">and</span> <span class="n">B</span><span class="p">.</span><span class="n">InsertTime</span><span class="o">&gt;</span><span class="k">Current_Date</span><span class="p">());</span>

<span class="k">INSERT</span> <span class="k">INTO</span> <span class="o">&lt;</span><span class="n">CSTG_SCHEMA</span><span class="o">&gt;&lt;</span><span class="k">TABLE</span><span class="o">&gt;</span> <span class="p">(</span><span class="o">&lt;</span><span class="n">columns</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">InsertTime</span><span class="p">)</span>
<span class="k">SELECT</span> <span class="o">&lt;</span><span class="n">columns</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">NOW</span><span class="p">()</span> <span class="k">FROM</span> <span class="o">&lt;</span><span class="n">STG_SCHEMA</span><span class="o">&gt;</span><span class="p">.</span><span class="o">&lt;</span><span class="k">TABLE</span><span class="o">&gt;</span> <span class="k">WHERE</span> <span class="n">InsertTime</span><span class="o">&gt;</span><span class="k">Current_Date</span><span class="p">();</span>
</code></pre></div>

<ul>
<li>全量</li>
</ul>
<p><em>有 InsertTime&gt;CurrentDate 时需要判断&nbsp;IsUpdate</em></p>
<div class="highlight"><pre><span></span><code><span class="n">IsUpdate</span><span class="o">=</span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s1">&#39;select count(1) Num from &lt;STG_SCHEMA&gt;.&lt;TABLE&gt; where InsertTime&gt;=current_date()&#39;</span><span class="p">);</span>
<span class="k">if</span> <span class="n">IsUpdate</span><span class="o">.</span><span class="n">collect</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;TRUNCATE TABLE &lt;CSTG_SCHEMA&gt;&lt;TABLE&gt;;&#39;</span><span class="p">)</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;INSERT INTO &lt;CSTG_SCHEMA&gt;&lt;TABLE&gt; (</span><span class="si">{</span><span class="n">columns</span><span class="si">}</span><span class="s1">,InsertTime) SELECT </span><span class="si">{</span><span class="n">columns</span><span class="si">}</span><span class="s1">, now() FROM &lt;STG_SCHEMA&gt;.&lt;TABLE&gt; where InsertTime&gt;Current_Date();&#39;</span><span class="p">)</span>
</code></pre></div>

<p><em>没有 InsertTime&gt;CurrentDate 不需要&nbsp;IsUpdate</em></p>
<div class="highlight"><pre><span></span><code><span class="k">TRUNCATE</span> <span class="k">TABLE</span> <span class="o">&lt;</span><span class="n">DWD_SCHEMA</span><span class="o">&gt;&lt;</span><span class="k">TABLE</span><span class="o">&gt;</span><span class="p">;</span>

<span class="k">INSERT</span> <span class="k">INTO</span> <span class="o">&lt;</span><span class="n">DWD_SCHEMA</span><span class="o">&gt;&lt;</span><span class="k">TABLE</span><span class="o">&gt;</span> <span class="p">(</span><span class="o">&lt;</span><span class="n">columns</span><span class="o">&gt;</span><span class="p">)</span>
<span class="k">SELECT</span> <span class="o">&lt;</span><span class="n">columns</span><span class="o">&gt;</span> <span class="k">FROM</span> <span class="o">&lt;</span><span class="n">CSTG_SCHEMA</span><span class="o">&gt;</span><span class="p">.</span><span class="o">&lt;</span><span class="k">TABLE</span><span class="o">&gt;</span><span class="p">;</span>
</code></pre></div>

<ul>
<li>Insert Table: <span class="caps">TXT</span></li>
</ul>
<p>法一：</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="o">*</span>

<span class="k">def</span> <span class="nf">insertTxT</span><span class="p">(</span><span class="n">FileName</span><span class="p">,</span> <span class="n">LandingTableName</span><span class="p">,</span> <span class="n">TableColumn</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">SaveDay</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
    <span class="n">schemalist</span> <span class="o">=</span> <span class="p">[];</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">TableColumn</span><span class="p">:</span> <span class="n">schemalist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">StructField</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">));</span>
    <span class="n">schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">(</span><span class="n">schemalist</span><span class="p">);</span>
    <span class="n">selectColumn</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="n">not_blank</span><span class="p">,</span> <span class="n">TableColumn</span><span class="p">))</span>
    <span class="n">df_DateLake</span><span class="o">=</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span><span class="s2">&quot;false&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;comment&quot;</span><span class="p">,</span><span class="s2">&quot;*&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;encoding&quot;</span><span class="p">,</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;sep&quot;</span><span class="p">,</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SapPath</span><span class="o">+</span><span class="n">FileName</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">selectColumn</span><span class="p">)</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">header</span><span class="p">:];</span>
    <span class="n">df_DateLake</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">df_DateLake</span><span class="p">)</span>
    <span class="n">df_DateLake</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;df_spark&quot;</span><span class="p">);</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">selectColumn</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;,InsertTime&#39;</span><span class="p">;</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;insert into </span><span class="si">{</span><span class="n">LandingTableName</span><span class="si">}</span><span class="s2">(</span><span class="si">{</span><span class="n">columns</span><span class="si">}</span><span class="s2">) select *, now() InsertTime from df_spark;&quot;</span><span class="p">);</span>
</code></pre></div>

<p>法二：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span>

<span class="n">TempPath</span><span class="o">=</span><span class="s2">&quot;dbfs:/FileStore/Temp&quot;</span>
<span class="n">TempFile</span><span class="o">=</span><span class="s2">&quot;/dbfs/FileStore/Temp/&quot;</span>

<span class="k">def</span> <span class="nf">insertTxT_Pandas</span><span class="p">(</span><span class="n">FileName</span><span class="p">,</span> <span class="n">LandingTableName</span><span class="p">,</span> <span class="n">TableColumn</span><span class="p">,</span><span class="n">RenameColumn</span><span class="p">,</span><span class="n">header</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">SaveDay</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
    <span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">rm</span><span class="p">(</span><span class="n">TempPath</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">mkdirs</span><span class="p">(</span><span class="n">TempPath</span><span class="p">)</span>
    <span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">cp</span><span class="p">(</span><span class="n">SapPath</span><span class="o">+</span><span class="n">FileName</span><span class="p">,</span> <span class="n">TempPath</span><span class="p">)</span>
    <span class="n">df_DateLake</span><span class="o">=</span><span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">TempFile</span><span class="o">+</span><span class="n">FileName</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="n">header</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">RenameColumn</span><span class="p">,</span><span class="n">skipinitialspace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">skip_blank_lines</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">error_bad_lines</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
    <span class="n">df_DateLake</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">df_DateLake</span><span class="p">);</span>
    <span class="n">df_DateLake</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;df_spark&quot;</span><span class="p">);</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="n">delInsertTime</span><span class="p">(</span><span class="n">TableColumn</span><span class="p">);</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;insert into </span><span class="si">{</span><span class="n">LandingTableName</span><span class="si">}</span><span class="s2">(</span><span class="si">{</span><span class="n">TableColumn</span><span class="si">}</span><span class="s2">) select </span><span class="si">{</span><span class="n">columns</span><span class="si">}</span><span class="s2">, now() InsertTime from df_spark;&quot;</span><span class="p">);</span>
</code></pre></div>

<p><strong><span class="caps">OPTIMIZE</span></strong></p>
<p>优化 Delta Lake&nbsp;数据的布局，优化数据子集或按列归置数据。</p>
<div class="highlight"><pre><span></span><code><span class="n">OPTIMIZE</span> <span class="k">table_name</span> <span class="p">[</span><span class="k">WHERE</span> <span class="n">predicate</span><span class="p">]</span>
  <span class="p">[</span><span class="n">ZORDER</span> <span class="k">BY</span> <span class="p">(</span><span class="n">col_name1</span> <span class="p">[,</span> <span class="p">...]</span> <span class="p">)</span> <span class="p">]</span>
</code></pre></div>

<p>启用自动优化</p>
<div class="highlight"><pre><span></span><code><span class="c1">-- 所有新表</span>
<span class="k">set</span> <span class="n">spark</span><span class="p">.</span><span class="n">databricks</span><span class="p">.</span><span class="n">delta</span><span class="p">.</span><span class="n">properties</span><span class="p">.</span><span class="k">defaults</span><span class="p">.</span><span class="n">autoOptimize</span><span class="p">.</span><span class="n">optimizeWrite</span> <span class="o">=</span> <span class="k">true</span><span class="p">;</span>
<span class="k">set</span> <span class="n">spark</span><span class="p">.</span><span class="n">databricks</span><span class="p">.</span><span class="n">delta</span><span class="p">.</span><span class="n">properties</span><span class="p">.</span><span class="k">defaults</span><span class="p">.</span><span class="n">autoOptimize</span><span class="p">.</span><span class="n">autoCompact</span> <span class="o">=</span> <span class="k">true</span><span class="p">;</span>
</code></pre></div>

<h2>Delta Live Table&nbsp;增量实时表</h2>
<div class="highlight"><pre><span></span><code><span class="k">CREATE</span> <span class="k">OR</span> <span class="n">REFRESH</span> <span class="n">STREAMING</span> <span class="n">LIVE</span> <span class="k">TABLE</span> <span class="n">customers_silver</span>
<span class="k">AS</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">STREAM</span><span class="p">(</span><span class="n">LIVE</span><span class="p">.</span><span class="n">customers_bronze</span><span class="p">)</span>
</code></pre></div>

<p>当为管道触发更新时，流式处理表或视图仅处理自上次更新以来到达的新数据。&nbsp;增量实时表运行时会自动跟踪已处理的数据。</p>
<h2><span class="caps">SQL</span></h2>
<ul>
<li>自定义变量</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">SET</span> <span class="n">delDate</span><span class="o">=</span><span class="k">current_date</span><span class="p">();</span>
<span class="k">set</span> <span class="n">tableList</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;TABLE1&#39;</span><span class="p">,</span> <span class="s1">&#39;TABLE2&#39;</span><span class="p">);</span>

<span class="k">delete</span> <span class="k">from</span> <span class="o">&lt;</span><span class="k">TABLE</span><span class="o">&gt;</span> <span class="k">where</span> <span class="n">insertDate</span><span class="o">=</span><span class="err">${</span><span class="n">hiveconf</span><span class="p">:</span><span class="n">delDate</span><span class="err">}</span> <span class="k">and</span> <span class="n">tablename</span> <span class="k">in</span> <span class="err">${</span><span class="n">hiveconf</span><span class="p">:</span><span class="n">tableList</span><span class="err">}</span><span class="p">;</span>
</code></pre></div>

<ul>
<li>自定义函数</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">CREATE</span> <span class="k">OR</span> <span class="k">REPLACE</span> <span class="k">FUNCTION</span> <span class="n">ToDouble</span><span class="p">(</span><span class="n">value</span> <span class="n">STRING</span><span class="p">)</span> <span class="k">RETURNS</span> <span class="n">DOUBLE</span> <span class="k">RETURN</span> <span class="n">double</span><span class="p">(</span><span class="k">replace</span><span class="p">(</span><span class="k">replace</span><span class="p">(</span><span class="k">replace</span><span class="p">(</span><span class="k">replace</span><span class="p">(</span><span class="k">trim</span><span class="p">(</span><span class="n">value</span><span class="p">),</span><span class="s1">&#39;-&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">),</span><span class="s1">&#39;&quot;&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">),</span><span class="s1">&#39;,&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">),</span><span class="s1">&#39;/&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">))</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">LandingTable</span> <span class="o">=</span> <span class="s1">&#39;STG.Inventory_CN&#39;</span>
<span class="n">CSTGTable</span> <span class="o">=</span> <span class="s1">&#39;CSTG.Inventory_CN&#39;</span>
<span class="n">TableColumn</span><span class="o">=</span><span class="s1">&#39;WhN, GRDate, PutawayStock&#39;</span>
<span class="n">CleanColumn</span><span class="o">=</span><span class="s2">&quot;WhN, TO_DATE(GRDate,&#39;yyyy/MM/dd&#39;) GRDate, ToDouble(PutawayStock) PutawayStock&quot;</span>

<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INSERT INTO </span><span class="si">{</span><span class="n">CSTGTable</span><span class="si">}</span><span class="s2">(</span><span class="si">{</span><span class="n">TableColumn</span><span class="si">}</span><span class="s2">) SELECT </span><span class="si">{</span><span class="n">CleanColumn</span><span class="si">}</span><span class="s2">, now() from </span><span class="si">{</span><span class="n">LandingTable</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">);</span>
</code></pre></div>

<ul>
<li><span class="caps">MERGE</span> <span class="caps">INTO</span></li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">with</span> <span class="err">{</span><span class="n">tablename</span><span class="err">}</span> <span class="k">as</span> <span class="p">(</span><span class="k">SELECT</span> <span class="n">EXPLODE</span><span class="p">(</span><span class="k">data</span><span class="p">)</span> <span class="k">data</span> <span class="k">FROM</span> <span class="n">json</span><span class="p">.</span><span class="o">`</span><span class="err">{</span><span class="n">jsonAddress</span><span class="err">}{</span><span class="n">Pre_Tablename</span><span class="err">}{</span><span class="n">tablename</span><span class="err">}</span><span class="o">`</span><span class="p">)</span>

<span class="n">merge</span> <span class="k">into</span> <span class="o">&lt;</span><span class="k">schema</span><span class="o">&gt;</span><span class="p">.</span><span class="n">Test</span> <span class="n">a</span>
<span class="k">using</span> <span class="err">{</span><span class="n">tablename</span><span class="err">}</span> <span class="n">b</span> <span class="k">on</span> <span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">id</span><span class="o">=</span><span class="n">b</span><span class="p">.</span><span class="n">id</span><span class="p">)</span>  
<span class="k">when</span> <span class="n">matched</span> <span class="k">then</span> <span class="k">update</span> 
  <span class="k">set</span> <span class="n">name</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="n">name</span>
<span class="k">when</span> <span class="k">not</span> <span class="n">matched</span> <span class="k">then</span> <span class="k">insert</span> 
  <span class="p">(</span><span class="n">id</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="k">values</span> <span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">id</span><span class="p">,</span> <span class="n">b</span><span class="p">.</span><span class="n">name</span><span class="p">);</span>
</code></pre></div>

<ul>
<li>Range join optimization&nbsp;范围联接优化</li>
</ul>
<p>适用范围：
1. 在区间范围内
2. 数据类型：numeric，date (days)，timestamp (second)
3. <span class="caps">INNER</span> <span class="caps">JOIN</span> / <span class="caps">LEFT</span> <span class="caps">OUTER</span> <span class="caps">JOIN</span> / <span class="caps">RIGHT</span> <span class="caps">OUTER</span> <span class="caps">JOIN</span>
4. Have a bin size tuning parameter 箱大小:&nbsp;建议将箱大小设置为值间隔的典型预期长度</p>
<div class="highlight"><pre><span></span><code><span class="c1">--- Point in interval range join</span>
<span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">points</span> <span class="k">JOIN</span> <span class="n">ranges</span> <span class="k">ON</span> <span class="n">points</span><span class="p">.</span><span class="n">p</span> <span class="k">BETWEEN</span> <span class="n">ranges</span><span class="p">.</span><span class="k">start</span> <span class="k">and</span> <span class="n">ranges</span><span class="p">.</span><span class="k">end</span><span class="p">;</span>

<span class="c1">--- Interval overlap range join</span>
<span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">r1</span> <span class="k">JOIN</span> <span class="n">r2</span> <span class="k">ON</span> <span class="n">r1</span><span class="p">.</span><span class="k">start</span> <span class="o">&lt;</span> <span class="n">r2</span><span class="p">.</span><span class="k">end</span> <span class="k">AND</span> <span class="n">r2</span><span class="p">.</span><span class="k">start</span> <span class="o">&lt;</span> <span class="n">r1</span><span class="p">.</span><span class="k">end</span><span class="p">;</span>
</code></pre></div>

<p>Enable range join using a range join&nbsp;hint</p>
<div class="highlight"><pre><span></span><code><span class="k">SELECT</span> <span class="cm">/*+ RANGE_JOIN(ranges, 10) */</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">points</span> <span class="k">JOIN</span> <span class="n">ranges</span> <span class="k">ON</span> <span class="n">points</span><span class="p">.</span><span class="n">p</span> <span class="o">&gt;=</span> <span class="n">ranges</span><span class="p">.</span><span class="k">start</span> <span class="k">AND</span> <span class="n">points</span><span class="p">.</span><span class="n">p</span> <span class="o">&lt;</span> <span class="n">ranges</span><span class="p">.</span><span class="k">end</span><span class="p">;</span>
</code></pre></div>

<ul>
<li>INFORMATION_SCHEMA </li>
</ul>
<p>The INFORMATION_SCHEMA is a <span class="caps">SQL</span> standard based schema, provided in every catalog created on Unity&nbsp;Catalog.</p>
<p>Table | Desc
| - | -
<span class="caps">CATALOGS</span> | Describes catalogs.
<span class="caps">TABLES</span> | Describes tables and views defined within the catalog.
<span class="caps">COLUMNS</span> | Describes columns of tables and views in the&nbsp;catalog.</p>
<p>https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-information-schema</p>
<div class="highlight"><pre><span></span><code><span class="k">SELECT</span> <span class="n">table_owner</span> <span class="k">FROM</span> <span class="n">information_schema</span><span class="p">.</span><span class="n">tables</span> <span class="k">WHERE</span> <span class="n">table_schema</span> <span class="o">=</span> <span class="s1">&#39;information_schema&#39;</span> <span class="k">AND</span> <span class="k">table_name</span> <span class="o">=</span> <span class="s1">&#39;columns&#39;</span><span class="p">;</span>

<span class="k">SELECT</span> <span class="n">ordinal_position</span><span class="p">,</span> <span class="k">column_name</span><span class="p">,</span> <span class="n">data_type</span> <span class="k">FROM</span> <span class="n">information_schema</span><span class="p">.</span><span class="n">tables</span>
</code></pre></div>

<p><em>踩坑: AnalysisException: [UC_NOT_ENABLED] Unity Catalog is not enabled on this&nbsp;cluster.</em></p>
<h2>Data Lake Storage&nbsp;Gen2</h2>
<p><span class="caps">SAS</span> Token: 共享访问签名是指向一个或多个存储资源的已签名 <span class="caps">URI</span>。 该 <span class="caps">URI</span> 包括的令牌包含一组特殊查询参数。&nbsp;该令牌指示客户端可以如何访问资源。 </p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">connectToDatalake</span><span class="p">(</span><span class="n">blob</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.account.auth.type.</span><span class="si">%s</span><span class="s2">.dfs.core.chinacloudapi.cn&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">blob</span><span class="p">),</span> <span class="s2">&quot;SAS&quot;</span><span class="p">)</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.sas.token.provider.type.</span><span class="si">%s</span><span class="s2">.dfs.core.chinacloudapi.cn&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">blob</span><span class="p">),</span> <span class="s2">&quot;org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider&quot;</span><span class="p">)</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.sas.fixed.token.</span><span class="si">%s</span><span class="s2">.dfs.core.chinacloudapi.cn&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">blob</span><span class="p">),</span> <span class="n">token</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">importExcelConfig</span><span class="p">(</span><span class="n">blob</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">_jsc</span><span class="o">.</span><span class="n">hadoopConfiguration</span><span class="p">()</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.account.auth.type.</span><span class="si">%s</span><span class="s2">.dfs.core.chinacloudapi.cn&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">blob</span><span class="p">),</span> <span class="s2">&quot;SAS&quot;</span><span class="p">)</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">_jsc</span><span class="o">.</span><span class="n">hadoopConfiguration</span><span class="p">()</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.sas.token.provider.type.</span><span class="si">%s</span><span class="s2">.dfs.core.chinacloudapi.cn&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">blob</span><span class="p">),</span> <span class="s2">&quot;org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider&quot;</span><span class="p">)</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">_jsc</span><span class="o">.</span><span class="n">hadoopConfiguration</span><span class="p">()</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.azure.sas.fixed.token.</span><span class="si">%s</span><span class="s2">.dfs.core.chinacloudapi.cn&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">blob</span><span class="p">),</span> <span class="n">token</span><span class="p">)</span>
</code></pre></div>

<p>OAuth: 使用 Azure Active Directory (Azure <span class="caps">AD</span>) 应用程序服务主体在 Azure&nbsp;存储帐户中装载数据以进行身份验证。</p>
<div class="highlight"><pre><span></span><code><span class="n">configs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;fs.azure.account.auth.type&quot;</span><span class="p">:</span> <span class="s2">&quot;OAuth&quot;</span><span class="p">,</span>
          <span class="s2">&quot;fs.azure.account.oauth.provider.type&quot;</span><span class="p">:</span> <span class="s2">&quot;org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider&quot;</span><span class="p">,</span>
          <span class="s2">&quot;fs.azure.account.oauth2.client.id&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;application-id&gt;&quot;</span><span class="p">,</span>
          <span class="s2">&quot;fs.azure.account.oauth2.client.secret&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;service-credential-key-name&gt;&quot;</span><span class="p">,</span>
          <span class="s2">&quot;fs.azure.account.oauth2.client.endpoint&quot;</span><span class="p">:</span> <span class="s2">&quot;https://login.microsoftonline.com/&lt;directory-id&gt;/oauth2/token&quot;</span><span class="p">}</span>

<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span>
  <span class="n">source</span> <span class="o">=</span> <span class="s2">&quot;abfss://&lt;container-name&gt;@&lt;storage-account-name&gt;.dfs.core.windows.net/&quot;</span><span class="p">,</span>
  <span class="n">mount_point</span> <span class="o">=</span> <span class="s2">&quot;/mnt/&lt;mount-name&gt;&quot;</span><span class="p">,</span>
  <span class="n">extra_configs</span> <span class="o">=</span> <span class="n">configs</span><span class="p">)</span>
</code></pre></div>

<h2><span class="caps">AWS</span>&nbsp;S3</h2>
<div class="highlight"><pre><span></span><code><span class="n">sc</span><span class="o">.</span><span class="n">_jsc</span><span class="o">.</span><span class="n">hadoopConfiguration</span><span class="p">()</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.s3n.awsAccessKeyId&quot;</span><span class="p">,</span> <span class="s2">&quot;xxx&quot;</span><span class="p">)</span>
<span class="n">sc</span><span class="o">.</span><span class="n">_jsc</span><span class="o">.</span><span class="n">hadoopConfiguration</span><span class="p">()</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;fs.s3n.awsSecretAccessKey&quot;</span><span class="p">,</span><span class="s2">&quot;xxx&quot;</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="s2">&quot;s3://&lt;bucketname&gt;/&lt;folder&gt;/&quot;</span><span class="p">))</span>
</code></pre></div>

<p>ADF不支持用S3作为Sink，只能通过Databricks将数据写入S3</p>
<div class="highlight"><pre><span></span><code><span class="n">pip</span> <span class="n">install</span> <span class="n">boto3</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">from</span> <span class="nn">boto3.session</span> <span class="kn">import</span> <span class="n">Session</span>
<span class="kn">from</span> <span class="nn">botocore.exceptions</span> <span class="kn">import</span> <span class="n">ClientError</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">Session</span><span class="p">(</span><span class="n">access_key</span><span class="p">,</span> <span class="n">secret_key</span><span class="p">)</span>
<span class="n">s3_client</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s1">&#39;s3&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">list_object</span><span class="p">(</span><span class="n">bucketName</span><span class="p">):</span>
    <span class="n">file_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">s3_client</span><span class="o">.</span><span class="n">list_objects_v2</span><span class="p">(</span><span class="n">Bucket</span><span class="o">=</span><span class="n">bucketName</span><span class="p">)</span>
    <span class="n">file_desc</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;Contents&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">file_desc</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;file_name: </span><span class="si">{}</span><span class="s1">, file_size: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="s1">&#39;Key&#39;</span><span class="p">],</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;Size&#39;</span><span class="p">]))</span>
        <span class="n">file_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="s1">&#39;Key&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">file_list</span>

<span class="k">def</span> <span class="nf">write_file</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">bucket</span><span class="p">,</span> <span class="n">content</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">s3_client</span><span class="o">.</span><span class="n">put_object</span><span class="p">(</span><span class="n">Body</span><span class="o">=</span><span class="n">content</span><span class="p">,</span> <span class="n">Key</span><span class="o">=</span><span class="n">file_name</span><span class="p">,</span> <span class="n">Bucket</span><span class="o">=</span><span class="n">bucket</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">ClientError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="kc">True</span>

<span class="k">def</span> <span class="nf">delete_file</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">bucket</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">s3_client</span><span class="o">.</span><span class="n">delete_object</span><span class="p">(</span><span class="n">Key</span><span class="o">=</span><span class="n">file_name</span><span class="p">,</span> <span class="n">Bucket</span><span class="o">=</span><span class="n">bucket</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">ClientError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="kc">True</span>

<span class="k">def</span> <span class="nf">copy_file</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">bucket</span><span class="p">,</span> <span class="n">source_file</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">s3_client</span><span class="o">.</span><span class="n">copy_object</span><span class="p">(</span><span class="n">Key</span><span class="o">=</span><span class="n">file_name</span><span class="p">,</span> <span class="n">Bucket</span><span class="o">=</span><span class="n">bucket</span><span class="p">,</span> <span class="n">CopySource</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">&#39;Bucket&#39;</span><span class="p">:</span> <span class="n">bucket</span><span class="p">,</span>
            <span class="s1">&#39;Key&#39;</span><span class="p">:</span> <span class="n">source_file</span>
        <span class="p">})</span>
    <span class="k">except</span> <span class="n">ClientError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="kc">True</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">copy_folder</span><span class="p">(</span><span class="n">bucket</span><span class="p">,</span> <span class="n">sourcefolder</span><span class="p">,</span> <span class="n">targetfolder</span><span class="p">,</span> <span class="n">deleteSource</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">file_list</span> <span class="o">=</span> <span class="n">list_object</span><span class="p">(</span><span class="n">bucket</span><span class="p">,</span> <span class="n">sourcefolder</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">file_list</span><span class="p">:</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">targetfolder</span><span class="o">+</span><span class="n">obj</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sourcefolder</span><span class="p">):]</span>
        <span class="n">copy_file</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">bucket</span><span class="p">,</span> <span class="n">obj</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">deleteSource</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sourcefolder</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">delete_file</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">bucket</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">BytesIO</span>

<span class="k">def</span> <span class="nf">create_csv</span><span class="p">(</span><span class="n">sourcedf</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">target_bucket</span><span class="p">):</span>
    <span class="n">csv_buffer</span> <span class="o">=</span> <span class="n">BytesIO</span><span class="p">()</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">sourcedf</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span>
    <span class="n">data</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">csv_buffer</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span> <span class="o">=</span> <span class="s1">&#39;utf_8_sig&#39;</span><span class="p">)</span>
    <span class="n">content</span> <span class="o">=</span> <span class="n">csv_buffer</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span>
    <span class="n">write_file</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">target_bucket</span><span class="p">,</span> <span class="n">content</span><span class="p">)</span>
</code></pre></div>

<h2><span class="caps">SQL</span> <span class="caps">SERVER</span></h2>
<ul>
<li><span class="caps">JDBC</span></li>
</ul>
<p>读取数据库</p>
<div class="highlight"><pre><span></span><code><span class="n">jdbcHostname</span> <span class="o">=</span> <span class="s1">&#39;xxx&#39;</span>
<span class="n">jdbcPort</span> <span class="o">=</span> <span class="s1">&#39;1433&#39;</span>
<span class="n">jdbcDatabase</span> <span class="o">=</span> <span class="s1">&#39;xxx&#39;</span>
<span class="n">properties</span> <span class="o">=</span> <span class="p">{</span>
<span class="s2">&quot;user&quot;</span> <span class="p">:</span> <span class="s1">&#39;xxx&#39;</span><span class="p">,</span>
<span class="s2">&quot;password&quot;</span> <span class="p">:</span> <span class="s1">&#39;xxx&#39;</span> <span class="p">}</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;jdbc:sqlserver://</span><span class="si">{0}</span><span class="s2">:</span><span class="si">{1}</span><span class="s2">;database=</span><span class="si">{2}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">jdbcHostname</span><span class="p">,</span><span class="n">jdbcPort</span><span class="p">,</span><span class="n">jdbcDatabase</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">jdbc</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span><span class="n">table</span><span class="o">=</span><span class="s1">&#39;xxx&#39;</span><span class="p">,</span><span class="n">properties</span> <span class="o">=</span> <span class="n">properties</span><span class="p">))</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">config_table</span> <span class="o">=</span> <span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span>
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;jdbc&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;url&quot;</span><span class="p">,</span> <span class="n">url</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;dbtable&quot;</span><span class="p">,</span> <span class="s1">&#39;xxx&#39;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="p">[</span><span class="s1">&#39;user&#39;</span><span class="p">])</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;password&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="p">[</span><span class="s1">&#39;password&#39;</span><span class="p">])</span>
  <span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">config_table</span><span class="p">)</span>
</code></pre></div>

<p>写入数据库</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">([</span>
  <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;TableName&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="n">nullable</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span>
  <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;SQLFlag&quot;</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">(),</span> <span class="n">nullable</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span>
<span class="p">])</span>

<span class="n">configList</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s1">&#39;DIM_Calendar&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="p">]</span>

<span class="n">config_df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">configList</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>
<span class="n">config_df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

<p><em>踩坑：StructField无法创建自增字段</em></p>
<div class="highlight"><pre><span></span><code><span class="k">SET</span> <span class="n">jdbcURL</span><span class="o">=`</span><span class="n">xxx</span><span class="o">`</span>

<span class="k">CREATE</span> <span class="k">OR</span> <span class="k">REPLACE</span> <span class="k">TABLE</span> <span class="o">&lt;</span><span class="k">Schema_Name</span><span class="o">&gt;</span><span class="p">.</span><span class="o">&lt;</span><span class="k">Table_Name</span><span class="o">&gt;</span>
  <span class="k">USING</span> <span class="n">JDBC</span>
<span class="k">OPTIONS</span> <span class="p">(</span>
  <span class="n">url</span> <span class="ss">&quot;${hiveconf:jdbcURL}&quot;</span><span class="p">,</span>
  <span class="n">dbtable</span> <span class="s1">&#39;xxx&#39;</span><span class="p">,</span>
  <span class="k">user</span> <span class="s1">&#39;xxx&#39;</span><span class="p">,</span>
  <span class="n">password</span> <span class="s1">&#39;xxx&#39;</span>
<span class="p">)</span> <span class="k">AS</span>
<span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">df_spark</span>
</code></pre></div>

<hr>
<h2>Cluster&nbsp;集群</h2>
<p>Cluster&nbsp;type:</p>
<ul>
<li>
<p>All-purpose cluster: can be shared by multiple users and are best for performing ad-hoc analysis, data exploration, or&nbsp;development. </p>
</li>
<li>
<p>Job cluster:  Job clusters terminate when your job ends, reducing resource usage and cost. Once you’ve completed implementing your processing and are ready to operationalize your code, switch to running it on a job&nbsp;cluster.</p>
</li>
</ul>
<p><em>踩坑：<span class="caps">ADF</span> 调用notebook 报错：Failure starting repl. Try detaching and re-attaching the notebook. 此类问题一般发生的原因为Driver node&nbsp;size不足/处于繁忙状态来不及处理请求。</em></p>
<ol>
<li>在ADF activity侧加上了自动重试 retry 次数。（当cmd1成功，cmd2失败，重生会导致cmd1反复执行，所以 <span class="caps">DML</span> 增量数据若要加retry 需要先 delete&nbsp;插入数据，全量数据truncate不回重复）</li>
<li>建议对于生产job任务采用Job cluster，而不是all purpose cluster。 Job cluster有更好的资源隔离，即用即删，成本也更便宜。但是job&nbsp;cluster背后要足量ip，ip不足会导致job直接挂掉无法修复，一般是有1024网段的databricks采用。</li>
</ol>
<p><em>踩坑：IpykernelUtils are causing the conflict and holding the python process. It is since 11.3 which has introduced Ipykernel&nbsp;shells</em></p>
<p>当存在在一个interactive cluster上同时跑多个并行notebooks的情况，IpykernelUtils 会引起冲突并且holding python process, 进而出现无法启动python&nbsp;kernel的错误。</p>
<p>在cluster添加如下spark configuration：
&#8220;spark.databricks.python.defaultPythonRepl&nbsp;pythonshell&#8221;</p>
<p><em>踩坑：Caused by: org.apache.hadoop.fs.PathIOException: `/[schemaName]/[tableName]/_SUCCESS&#8217;: Input/output error: Parallel access to the create path detected. Failing request to honor single writer&nbsp;semantics</em></p>
<p>限制Spark往HDFS写出数据时生成_SUCCESS文件&nbsp;（未验证）</p>
<div class="highlight"><pre><span></span><code><span class="k">set</span> <span class="n">mapreduce</span><span class="p">.</span><span class="n">fileoutputcommitter</span><span class="p">.</span><span class="n">marksuccessfuljobs</span><span class="o">=</span><span class="k">false</span>
</code></pre></div>

<hr>
<div class="highlight"><pre><span></span><code><span class="c1"># reading the CDL blob storage using scan_read(SCAN package)</span>
<span class="kn">from</span> <span class="nn">sca_read.loader</span> <span class="kn">import</span> <span class="n">helper</span><span class="p">,</span> <span class="n">getSysttemRelatedTables</span>

<span class="n">display</span><span class="p">(</span><span class="n">getSystemRelatedTables</span><span class="p">(</span><span class="n">storageaccount</span><span class="o">=</span><span class="s2">&quot;xxx&quot;</span><span class="p">,</span> <span class="n">container</span><span class="o">=</span><span class="s2">&quot;xxx&quot;</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;/xx/xx/xx&quot;</span><span class="p">,</span> <span class="n">returnType</span><span class="o">=</span><span class="s2">&quot;pandas_dataframe&quot;</span><span class="p">))</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">sdf_SAP</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;select * from delta.`abfss://xxx@xxx.net`&quot;&quot;&quot;</span><span class="p">)</span>

<span class="n">sdf_SAP</span><span class="o">.</span><span class="n">display</span><span class="p">()</span> <span class="c1">## 点击download下载表格</span>
</code></pre></div>

<p>underscore variables are related to the pipelining process(sap =&gt; L0), don&#8217;t have any content in&nbsp;it.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># creation of a tempview / caching the data</span>
<span class="n">sdf_SAP</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;SAP_AUFK&quot;</span><span class="p">)</span>
<span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">cacheTable</span><span class="p">(</span><span class="s2">&quot;SAP_AUFK&quot;</span><span class="p">)</span>
<span class="c1"># SAP_AUFK can be called in spark.sql</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sdf_SAP</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1"># access a storage account</span>
<span class="n">Storage_account</span> <span class="o">=</span> <span class="s2">&quot;xxx&quot;</span>
<span class="n">Container</span> <span class="o">=</span> <span class="s2">&quot;xxx&quot;</span>
<span class="n">SAS_Token</span> <span class="o">=</span> <span class="n">dbutils</span><span class="o">.</span><span class="n">secrets</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;xxx&quot;</span><span class="p">,</span> <span class="s2">&quot;xxx&quot;</span><span class="p">)</span>
<span class="n">configOption</span> <span class="o">=</span> <span class="s2">&quot;xxx&quot;</span>
<span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">configOption</span><span class="p">,</span> <span class="n">SAS_Token</span><span class="p">)</span>
<span class="n">fileSystemUrl</span> <span class="o">=</span> <span class="s2">&quot;xxx&quot;</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="n">fileSystemUrl</span><span class="p">)</span> <span class="c1">#list files</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1"># display tables, paths, levels</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="k">def</span> <span class="nf">showAllTables</span><span class="p">():</span>
  <span class="n">l0Tables</span> <span class="o">=</span> <span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="n">L0_PATH</span><span class="p">)</span>
  <span class="n">dfL0</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">l0Tables</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1"># print schema</span>
<span class="n">sdf_SAP</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;Record_ID&quot;</span><span class="p">,</span> <span class="s2">&quot;DATE_CREATED&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="s2">&quot;Record_ID == &#39;1&#39;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.window</span> <span class="kn">import</span> <span class="n">window</span>
<span class="c1"># group by</span>
<span class="n">windowSpec</span> <span class="o">=</span> <span class="n">Window</span><span class="o">.</span><span class="n">partitionBy</span><span class="p">(</span><span class="s2">&quot;Record_ID&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="s2">&quot;Record_ID&quot;</span><span class="p">)</span>
<span class="c1"># expansion</span>
<span class="n">dfExplode</span> <span class="o">=</span> <span class="n">dfForExplode</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;SEQ_NO&#39;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">row_number</span><span class="p">()</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">windowSpec</span><span class="p">))</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pyspark</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># writes the table in sql server and implements the right table schema</span>
<span class="k">def</span> <span class="nf">scan_pushDfToSQL</span><span class="p">(</span>
  <span class="n">df</span><span class="p">:</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">dataframe</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
  <span class="n">sqlTable</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span>
  <span class="n">database</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span>
  <span class="n">sqlserver</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span>

<span class="n">sql_table_name</span> <span class="o">=</span> <span class="s2">&quot;SIDE_DEPARTMENT_PROJECT_tableName_DEV &quot;</span> <span class="c1"># naming conventions</span>
<span class="n">scan_pushDfToSQL</span><span class="p">(</span><span class="n">df</span> <span class="o">=</span> <span class="n">sdf_order_issues_inves</span><span class="p">,</span> <span class="n">sqlTable</span> <span class="o">=</span> <span class="n">sql_table_name</span><span class="p">,</span> <span class="n">database</span> <span class="o">=</span> <span class="s2">&quot;LEIDEN&quot;</span><span class="p">,</span> <span class="n">modeType</span> <span class="o">=</span> <span class="s2">&quot;overwrite&quot;</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<h3>Spark</h3>
<p>Spark 是使用 scala 实现的基于内存计算的大数据开源集群计算环境.提供了 java,scala, python,R&nbsp;等语言的调用接口。</p>
<p>Spark专门用于大数据量下的迭代式计算，将数据一直缓存在内存中,直到计算得到最后的结果,再将结果写入到磁盘,所以多次运算的情况下,Spark&nbsp;是比较快的。</p>
<ul>
<li>Spark <span class="caps">SQL</span>: 提供了类 <span class="caps">SQL</span> 的查询,返回 Spark-DataFrame 的数据结构(类似&nbsp;Hive)</li>
<li>Spark Streaming: 流式计算,主要用于处理线上实时时序数据(类似&nbsp;storm)</li>
<li>MLlib:&nbsp;提供机器学习的各种模型和调优</li>
<li>GraphX: 提供基于图的算法,如&nbsp;PageRank</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">Select</span> <span class="n">id</span><span class="p">,</span> <span class="k">result</span> <span class="k">from</span> <span class="n">exams</span> <span class="k">where</span> <span class="k">result</span> <span class="o">&gt;</span> <span class="mi">70</span> <span class="k">order</span> <span class="k">by</span> <span class="k">result</span>

<span class="n">spark</span><span class="p">.</span><span class="k">table</span><span class="p">(</span><span class="ss">&quot;exam&quot;</span><span class="p">).</span><span class="k">select</span><span class="p">(</span><span class="ss">&quot;id&quot;</span><span class="p">,</span> <span class="ss">&quot;result&quot;</span><span class="p">).</span><span class="k">where</span><span class="p">(</span><span class="ss">&quot;result &gt; 70&quot;</span><span class="p">).</span><span class="n">orderBy</span><span class="p">(</span><span class="ss">&quot;result&quot;</span><span class="p">)</span>
</code></pre></div>

<p>SparkSQL中的三种Join:</p>
<ul>
<li>Broadcast Join&nbsp;小表对大表</li>
</ul>
<p>将小表的数据分发到每个节点上，供大表使用。executor存储小表的全部数据，牺牲空间，换取shuffle操作大量的耗时。</p>
<p>被广播的表首先被collect到driver段，然后被冗余分发到每个executor上，所以当表比较大时，采用broadcast&nbsp;join会对driver端和executor端造成较大的压力。</p>
<p>基表不能被广播，比如 left outer join&nbsp;时，只能广播右表</p>
<ul>
<li>Shuffle Hash&nbsp;Join</li>
</ul>
<p>利用key相同必然分区相同的这个原理，先对两张表分别按照join keys进行重分区（shuffle），再对两个表中相对应分区的数据分别进行Hash Join（先将小表分区构造为一张hash表，然后根据大表分区中记录的join&nbsp;keys值拿出来进行匹配）</p>
<p>分区的平均大小不超过spark.sql.autoBroadcastJoinThreshold所配置的值，默认是10M</p>
<ul>
<li>Sort Merge Join&nbsp;大表对大表</li>
</ul>
<p>将两张表按照join keys进行了重新shuffle，保证join&nbsp;keys值相同的记录会被分在相应的分区。分区后对每个分区内的数据进行排序，排序后再对相应的分区内的记录进行连接</p>
<p>https://blog.csdn.net/hellojoy/article/details/113665938</p>
<p>踩坑：There is not enough memory to build the hash&nbsp;map</p>
<p><em>If the estimated size of one of the DataFrames is less than the autoBroadcastJoinThreshold, Spark may use BroadcastHashJoin to perform the join. If the available nodes do not have enough resources to accommodate the broadcast DataFrame, your job fails due to an out of memory&nbsp;error.</em></p>
<p>In Databricks Runtime 7.0 and above, set the join type to SortMergeJoin with join hints&nbsp;enabled.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># disable broadcast</span>
<span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;spark.sql.autoBroadcastJoinThreshold&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>

<h3>DataFrame</h3>
<p>A DataFrame is a distributed collection of data grouped into named&nbsp;columns</p>
<p>DataFrame是一种表格型数据结构，它含有一组有序的列，每列可以是不同的值。DataFrame的行索引是index，列索引是columns。</p>
<div class="highlight"><pre><span></span><code><span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;state&#39;</span><span class="p">:[</span><span class="s1">&#39;Ohio&#39;</span><span class="p">,</span><span class="s1">&#39;Ohio&#39;</span><span class="p">,</span><span class="s1">&#39;Ohio&#39;</span><span class="p">,</span><span class="s1">&#39;Nevada&#39;</span><span class="p">,</span><span class="s1">&#39;Nevada&#39;</span><span class="p">],</span>
    <span class="s1">&#39;year&#39;</span><span class="p">:[</span><span class="mi">2000</span><span class="p">,</span><span class="mi">2001</span><span class="p">,</span><span class="mi">2002</span><span class="p">,</span><span class="mi">2001</span><span class="p">,</span><span class="mi">2002</span><span class="p">],</span>
<span class="p">}</span>
<span class="n">frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>

<p>A schema defines the column names and types of a&nbsp;DataFrame</p>
<p>DataFrame transformations are methods that return a new DataFrame and are lazily&nbsp;evaluated</p>
<p>DataFrame actions are methods that trigger computation. An action is needed to trigger the execution of any DataFrame&nbsp;transformations</p>
<div class="highlight"><pre><span></span><code><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;result&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="s2">&quot;result &gt; 70&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="s2">&quot;result&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

<hr>
<h2>Diagnostic&nbsp;setting</h2>
<p>Azure portal -&gt; Databricks -&gt; Monitoring -&gt; Diagnostic&nbsp;settings</p>
<p>workspace的监控日志，比如谁生成/删除一个token</p>
<h2>Unity Catalog&nbsp;数据治理组件</h2>
<p>功能：
* 治理所有数据资产：数仓，库表，数据湖，文件，机器学习模型，dashboard, notebook
* 数据血缘
* 安全策略
* ABAC权限管理，表级、列级权限控制（<span class="caps">WIP</span>）
*&nbsp;数据审计，数据共享</p>
<p>Hierarchy of primary data objects flows 主要数据对象的层次结构:
* Metastore 元存储：元数据的顶级容器，用于管理对数据资产的访问的权限，用户可以查看分配了USAGE数据权限的所有目录。
* Catalog 目录
* Schema 架构/数据库
* Table&nbsp;表/视图</p>
    </div><!-- /.entry-content -->
    <footer class="post-meta">
        <span class="meta-prep">Category:</span>
        <abbr class="category">
            <a href="/category/cloud.html">Cloud</a>
        </abbr>
        <p>
        <span class="meta-prep">Author: </span><span>Yoga</span>
      </p>
    </footer>
    <!-- <section id="respond">
        <div id="disqus_thread">
        <script type="text/javascript">
        var disqus_identifier = "microsoft-azure-databricks.html";
        (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
        </script>
        </div>

    </section> -->
</section>


        </section><!-- #content -->
        <section id="widgets" class="grid col-300 fit" >
            <!--
            <section id="widget-search" class="widget-wrapper widget_search">

                <form id="searchform" action="http://www.google.com/search" method="get">
                    <input id="q" class="field" type="text" placeholder="Search Blog" name="q" ></input>
                    <input id="ie" name="ie" type="hidden" value="utf-8" ></input>
                    <input id="oe" name="oe" type="hidden" value="utf-8" ></input>
                    <input id="channel" name="channel" type="hidden" value="suggest" ></input>
                    <input id="searchsubmit" class="submit" type="submit" value="">
                </form>
            </section>
            -->
            <section id="widget-category" class="widget-wrapper widget_archive">
                <div class="widget-title">
                    Article
                </div>
                <ul>
                        <li>
                          <a href="/category/analytics.html" >Analytics</a>
                        </li>
                        <li>
                          <a href="/category/angular.html" >Angular</a>
                        </li>
                        <li>
                          <a href="/category/backend.html" >Backend</a>
                        </li>
                        <li>
                          <a href="/category/cloud.html" >Cloud</a>
                        </li>
                        <li>
                          <a href="/category/frontend.html" >Frontend</a>
                        </li>
                        <li>
                          <a href="/category/ios.html" >IOS</a>
                        </li>
                        <li>
                          <a href="/category/javascript.html" >Javascript</a>
                        </li>
                        <li>
                          <a href="/category/programming.html" >Programming</a>
                        </li>
                        <li>
                          <a href="/category/project.html" >Project</a>
                        </li>
                        <li>
                          <a href="/category/react.html" >React</a>
                        </li>
                </ul>
            </section>

            <section id="widget-tagcloud" class="widget-wrapper widget_archive">
                <div class="widget-title">
                    Tagcloud
                </div>
                <div>
                        <span><a href="/tag/dva.html">DVA</a></span>
                        <span><a href="/tag/ml.html">ML</a></span>
                        <span><a href="/tag/sql.html">sql</a></span>
                        <span><a href="/tag/azure.html">Azure</a></span>
                        <span><a href="/tag/database.html">database</a></span>
                        <span><a href="/tag/antv.html">AntV</a></span>
                        <span><a href="/tag/next.html">Next</a></span>
                        <span><a href="/tag/nest.html">Nest</a></span>
                        <span><a href="/tag/etl.html">ETL</a></span>
                        <span><a href="/tag/aws.html">AWS</a></span>
                        <span><a href="/tag/deep-learning.html">Deep Learning</a></span>
                        <span><a href="/tag/java.html">Java</a></span>
                        <span><a href="/tag/flutter.html">Flutter</a></span>
                        <span><a href="/tag/typescript.html">TypeScript</a></span>
                        <span><a href="/tag/angular.html">Angular</a></span>
                        <span><a href="/tag/cicd.html">CI/CD</a></span>
                        <span><a href="/tag/devtools.html">DevTools</a></span>
                        <span><a href="/tag/microsoft.html">Microsoft</a></span>
                        <span><a href="/tag/egg.html">egg</a></span>
                        <span><a href="/tag/tableau.html">Tableau</a></span>
                        <span><a href="/tag/sap.html">SAP</a></span>
                        <span><a href="/tag/token.html">Token</a></span>
                        <span><a href="/tag/regexp.html">Regexp</a></span>
                        <span><a href="/tag/unit-test.html">Unit test</a></span>
                        <span><a href="/tag/docker.html">Docker</a></span>
                        <span><a href="/tag/nginx.html">Nginx</a></span>
                        <span><a href="/tag/nodejs.html">nodeJS</a></span>
                        <span><a href="/tag/sails.html">sails</a></span>
                        <span><a href="/tag/wechat.html">wechat</a></span>
                        <span><a href="/tag/jmeter.html">Jmeter</a></span>
                        <span><a href="/tag/html2canvas.html">HTML2Canvas</a></span>
                        <span><a href="/tag/swift.html">Swift</a></span>
                        <span><a href="/tag/jenkins.html">Jenkins</a></span>
                        <span><a href="/tag/proxy.html">proxy</a></span>
                        <span><a href="/tag/js.html">JS</a></span>
                        <span><a href="/tag/event.html">event</a></span>
                        <span><a href="/tag/gtm.html">GTM</a></span>
                        <span><a href="/tag/algorithm.html">Algorithm</a></span>
                        <span><a href="/tag/echarts.html">Echarts</a></span>
                        <span><a href="/tag/react-admin.html">React-Admin</a></span>
                        <span><a href="/tag/rest.html">Rest</a></span>
                        <span><a href="/tag/react.html">React</a></span>
                        <span><a href="/tag/hook.html">hook</a></span>
                        <span><a href="/tag/flux.html">Flux</a></span>
                        <span><a href="/tag/redux.html">Redux</a></span>
                        <span><a href="/tag/es6.html">ES6</a></span>
                        <span><a href="/tag/route.html">Route</a></span>
                        <span><a href="/tag/component.html">Component</a></span>
                        <span><a href="/tag/ref.html">Ref</a></span>
                        <span><a href="/tag/ajax.html">AJAX</a></span>
                        <span><a href="/tag/form.html">Form</a></span>
                        <span><a href="/tag/jsx.html">JSX</a></span>
                        <span><a href="/tag/virtual-dom.html">Virtual Dom</a></span>
                        <span><a href="/tag/express.html">Express</a></span>
                        <span><a href="/tag/javascript.html">Javascript</a></span>
                        <span><a href="/tag/css.html">CSS</a></span>
                        <span><a href="/tag/design-pattern.html">design pattern</a></span>
                </div>
            </section>


            <section id="widget-links" class="widget-wrapper widget_archive">
                <div class="widget-title">
                    Links
                </div>
                <ul>
                        <li><a href="https://github.com/yogagii">Github</a></li>
                        <li><a href="https://preview-static.clewm.net/cli/view-doc/view.html?url=https%3A%2F%2Fncstatic.clewm.net%2Frsrc%2F2021%2F0510%2F20%2F013c587ff42ef5f36ccb923c9d7a3765.pdf">UI/UX/Frontend/Game Design</a></li>
                        <li><a href="https://preview-static.clewm.net/cli/view-doc/view.html?url=https%3A%2F%2Fncstatic.clewm.net%2Frsrc%2F2021%2F0510%2F19%2F64852862e888e4db944b06eea147d035.pdf">Industrial Design Portfolio</a></li>
                </ul>
            </section>
            
        </section><!-- widgets -->
    </section><!-- /#wrapper -->
    <footer id="footer" class="clearfix"><section class="footer-wrapper">
        <div class="grid col-940" >
            <div class="grid col-540"></div>
            <div class="grid col-380 fit" >
                <ul class="social-icons">
                    <!-- TO BE CONTINUED -->
                </ul>
            </div>
        </div>

        <div class="grid col-300 copyright" >
            <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/" rel="license">
                <img src="http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" style="border-width:0" alt="知识共享许可协议"></img>
            </a>
        </div>
        <div class="grid col-300 ">

        </div>
        <div class="grid col-300 fit powered">
            Powered by <a href="http://getpelican.com/">Pelican</a> <br />
            which takes great advantage of <a href="http://python.org">Python</a>
        </div>
    </section></footer>
</div>
</body>
</html>